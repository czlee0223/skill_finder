{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dedcb5f3-35be-4311-8a35-b59c222fe3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import numpy as np\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "service = Service(executable_path=r\"C:\\Users\\ZACK LEE\\Documents\\Coding\\chromedriver_win32\\chromedriver.exe\")\n",
    "op = webdriver.ChromeOptions()\n",
    "op.add_argument('headless')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9feacda-6ee1-4587-9b2f-9d1ceaa04411",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGIN_DETAILS_FILE_PATH = r\"C:\\Users\\ZACK LEE\\Documents\\Username&Password.txt\"\n",
    "websites = { \n",
    "                'jobstreet': {\n",
    "                    \n",
    "                                'url' : \"https://myjobstreet.jobstreet.com.my/home/login.php?site=my&language_code=3\",\n",
    "                                'login_id' : \"login_id\",\n",
    "                                'password_id' : \"password\",\n",
    "                                'btn_id' : \"btn_login\",\n",
    "                                'search_content' : \"https://www.jobstreet.com.my/en/job-search/data-science-jobs/\",\n",
    "                                'job_lists_path' : '//*[@id=\"jobList\"]/div[2]/div[2]/div',\n",
    "                                'job_path' : 'div',\n",
    "                                'job_url_path' : 'div/div/article/div/div/div[1]/div[1]//a[@href]',\n",
    "                                'role_path' : 'div/div/article/div/div/div[1]/div[1]//h1/a/div/span',\n",
    "                                'company_path' : 'div/div/article/div/div/div[1]/div[1]/div[3]/span',\n",
    "                                'location_path' : 'div/div/article/div/div/div[1]/div[1]/span/span',\n",
    "                                'description_path' : '//*[@id=\"contentContainer\"]/div/div[2]/div/div[1]/div',\n",
    "                                'next_page_first' : '//*[@id=\"jobList\"]/div[2]/div[3]/div/a',\n",
    "                                'next_page' : '//*[@id=\"jobList\"]/div[2]/div[3]/div/a[2]'\n",
    "                },\n",
    "                \n",
    "                'linkedin' : {\n",
    "                    \n",
    "                                'url' : \"https://www.linkedin.com/checkpoint/rm/sign-in-another-account?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin\",\n",
    "                                'login_id' : \"username\",\n",
    "                                'password_id' : \"password\",\n",
    "                                'btn_id' : \"login__form_action_container\",\n",
    "                                'search_content' : \"https://www.linkedin.com/jobs/search/?keywords=data%20science\",\n",
    "                                'job_lists_path' : '/html/body/div[6]/div[3]/div[3]/div[2]/div/section[1]/div/div/ul',\n",
    "                                'job_path' : 'li',\n",
    "                                'job_url_path' : 'div/div/div[1]/div[2]/div[1]/a',\n",
    "                                'role_path' : 'div/div/div[1]/div[2]/div[1]/a',\n",
    "                                'company_path' : 'div/div/div[1]/div[2]/div[2]/a',\n",
    "                                'location_path' : 'div/div/div[1]/div[2]/div[3]/ul/li',\n",
    "                                'description_path' : '//*[@id=\"job-details\"]/span'\n",
    "                    \n",
    "                }\n",
    "}\n",
    "#ember186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d2bf1e92-3a44-4561-8e4e-5dd2b4ec235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_login_details(path):\n",
    "    with open(path, \"r\") as file1:\n",
    "    # Reading form a file\n",
    "        username = file1.readline()\n",
    "        password = file1.readline()\n",
    "    return username,password\n",
    "\n",
    "def login(driver,un,p,webname):\n",
    "    url = websites[webname]['url']\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    driver.get(url)\n",
    "    username = driver.find_element(By.ID,websites[webname]['login_id'])\n",
    "    username.send_keys(un)\n",
    "    password = driver.find_element(By.ID,websites[webname]['password_id'])\n",
    "    password.send_keys(p)\n",
    "    \n",
    "    ## for jobstreet\n",
    "    # driver.find_element(By.ID,websites[webname]['btn_id']).click()\n",
    "    \n",
    "    # for linkedin\n",
    "    driver.find_element(By.CLASS_NAME,websites[webname]['btn_id']).click()\n",
    "    \n",
    "def search(driver,webname):\n",
    "    time.sleep(5)\n",
    "    driver.get(websites[webname]['search_content'])\n",
    "\n",
    "def get_jobs(driver,job_details,webname):\n",
    "\n",
    "    try:\n",
    "        job_lists = WebDriverWait(driver,30).until(EC.presence_of_element_located((By.XPATH, websites[webname]['job_lists_path'])))\n",
    "    except:\n",
    "        driver.get(driver.current_url);\n",
    "        job_lists = WebDriverWait(driver,30).until(EC.presence_of_element_located((By.XPATH, websites[webname]['job_lists_path'])))\n",
    "    # job_lists = driver.find_element(By.XPATH,'//*[@id=\"jobList\"]/div[2]/div[2]/div')\n",
    "    jobs = job_lists.find_elements(By.XPATH,websites[webname]['job_path'])\n",
    "    # print(len(jobs))\n",
    "    for job in jobs:\n",
    "        ## skip the current data if error occurs while collecting it\n",
    "        try:\n",
    "            url = job.find_element(By.XPATH,websites[webname]['job_url_path']).get_attribute(\"href\")\n",
    "            role = job.find_element(By.XPATH,websites[webname]['role_path']).text\n",
    "            company = job.find_element(By.XPATH,websites[webname]['company_path']).text\n",
    "            location = job.find_element(By.XPATH,websites[webname]['location_path']).text\n",
    "            # print(role)\n",
    "        except:\n",
    "            continue\n",
    "        job_details.update({url:{'company':company,'location':location,'role':role}})\n",
    "\n",
    "        \n",
    "def get_description(driver,job_dict,webname):\n",
    "    \n",
    "    for url in list(job_dict.keys()):\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            driver.find_element(By.XPATH,'/html/body/div[6]/div[3]/div/div[1]/div[1]/div/div[2]/footer/button').click()\n",
    "            description = WebDriverWait(driver,30).until(EC.presence_of_element_located((By.XPATH, websites[webname]['description_path']))).text\n",
    "            \n",
    "        except:\n",
    "            driver.get(url)\n",
    "            driver.find_element(By.XPATH,'/html/body/div[6]/div[3]/div/div[1]/div[1]/div/div[2]/footer/button').click()\n",
    "            description = WebDriverWait(driver,30).until(EC.presence_of_element_located((By.XPATH,  websites[webname]['description_path']))).text\n",
    "        print(description)\n",
    "        \n",
    "        job_dict.get(url).update({\"description\":description})\n",
    "        \n",
    "    \n",
    "def load_next_page(driver,first,webname):\n",
    "    \n",
    "    if(first):\n",
    "        next = driver.find_element(By.XPATH, websites[webname]['next_page_first'])\n",
    "        next.click()\n",
    "    else:\n",
    "        next = driver.find_element(By.XPATH, websites[webname]['next_page'])\n",
    "        next.click()\n",
    "        \n",
    "def scroll_down(driver):\n",
    "    \n",
    "    try:\n",
    "        job_lists = WebDriverWait(driver,30).until(EC.presence_of_element_located((By.XPATH, websites[webname]['job_lists_path'])))\n",
    "    except:\n",
    "        driver.get(driver.current_url);\n",
    "        job_lists = WebDriverWait(driver,30).until(EC.presence_of_element_located((By.XPATH, websites[webname]['job_lists_path'])))\n",
    "    # job_lists = driver.find_element(By.XPATH,websites[webname]['job_lists_path'])\n",
    "    jobs = job_lists.find_elements(By.XPATH,websites[webname]['job_path'])\n",
    "    # print(len(jobs))\n",
    "    for job in jobs:\n",
    "        name = job.get_attribute('id');\n",
    "        driver.execute_script(f'document.querySelector(\"#{name} > div > div\").scrollIntoView();')\n",
    "        time.sleep(1)\n",
    "        \n",
    "def load_next_page_linkedin(driver):\n",
    "  #loads next page for url retrival\n",
    "    curr= driver.find_element(By.XPATH,'//*[@aria-current=\"true\"]').text\n",
    "    next = driver.find_element(By.XPATH,f'//*[@aria-label=\"Page {int(curr)+1}\"]')\n",
    "    next.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679d76c7-f2d2-495f-8057-ca600bc2f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "webname = 'linkedin'\n",
    "driver = webdriver.Chrome(service=service)\n",
    "username,password = get_login_details(LOGIN_DETAILS_FILE_PATH)\n",
    "job_dict = {}\n",
    "login(driver,username,password,webname)\n",
    "search(driver,webname)\n",
    "isfirst = True\n",
    "i = 0\n",
    "while True:\n",
    "    i+=1\n",
    "    print(i)\n",
    "    print(len(list(job_dict)))\n",
    "    try:\n",
    "        scroll_down(driver)\n",
    "        get_jobs(driver,job_dict,webname)\n",
    "        # load_next_page(driver,isfirst,webname)\n",
    "        load_next_page_linkedin(driver)\n",
    "    except:\n",
    "\n",
    "        break\n",
    "    isfirst = False\n",
    "# get_description(driver,job_dict,webname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "91344b98-2b72-4c35-b606-824f41f2eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save(final_file):\n",
    "    with open(f'./data/job_new_dict_linkedin.p', 'wb') as fp:\n",
    "        pickle.dump(final_file,file=fp,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "def load():\n",
    "    with open('./data/job_dict.p', 'rb') as fp:\n",
    "        job_dict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "28f647d3-244e-484f-9834-a36d4ea6704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "35d0f69f-b7f0-46ec-a680-1c114eedfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "webname = 'linkedin'\n",
    "driver = webdriver.Chrome(service=service)\n",
    "username,password = get_login_details(LOGIN_DETAILS_FILE_PATH)\n",
    "login(driver,username,password,webname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48816b-3a3f-4b00-8c74-e00e5134c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_description(driver,job_dict,webname)\n",
    "# driver.get(list(job_dict.keys())[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
