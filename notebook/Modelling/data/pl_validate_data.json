[
    [
        "Job Description Job Responsibilities: Work closely with the data analysts to translate requirement into data feeds Ensures Non Functional Requirements can be met within the proposed solution. Documents the ETL components ready for implementation. Designs and documents pipelines in the context of the overall architecture. Develops ETL pipelines and transformation logic. Peer review Pipeline code and ensure standards are met. Develops complex SQL scripts, stored procedures. Understands SSIS ETL pipelines and can update and maintain the processes. Expert skills in development of python scripts and use of standard libraries. Expands the ETL frameworks in line with the architecture requirements.  Job Requirements: Bachelor's or master's degree in data science, information technology or equivalent 3+ years of working experience in Data Engineering and/or Software Engineering, 2+ years of recent Python development experience or equivalent programming language (Java, C#, Scala) Advanced knowledge of Standard Query Language (SQL) Advantageous to have Bigdata development experience e.g. Spark, Storm or similar Experience working with Data Lakes ideally Azure Data Lake. MSSQL and SSIS experience a plus AZURE Synapse experience a plus How to Apply?  To apply, please click \"APPLY NOW\". Data provided is for recruitment purposes only.  Due to the volume of applications received, we regret to inform you that only shortlisted candidates will be notified.  JTK Number: JTKSM 995 | Company Registration Number: 201301019088 (1048918-T)If this job isn't quite right for you, but you know someone who would be great at this role, why not take advantage of our referral scheme? We offer MYR500 in shopping vouchers for every referred candidate who we place in a role. Terms & Conditions Apply. https://www.ambition.com.my/refer-a-friend Additional Information Career Level Non-Executive Qualification Bachelor's Degree, Post Graduate Diploma, Professional Degree Years of Experience 2 years Job Type Full-Time Job Specializations Computer/Information Technology, IT-Software",
        {
            "entities": [
                [
                    445,
                    448,
                    "PROGLANG"
                ],
                [
                    583,
                    589,
                    "PROGLANG"
                ],
                [
                    719,
                    727,
                    "EDUCATION"
                ],
                [
                    733,
                    739,
                    "EDUCATION"
                ],
                [
                    902,
                    908,
                    "PROGLANG"
                ],
                [
                    968,
                    972,
                    "PROGLANG"
                ],
                [
                    974,
                    976,
                    "PROGLANG"
                ],
                [
                    978,
                    983,
                    "PROGLANG"
                ],
                [
                    1032,
                    1035,
                    "PROGLANG"
                ],
                [
                    1094,
                    1099,
                    "TOOL"
                ],
                [
                    1161,
                    1166,
                    "TOOL"
                ],
                [
                    1903,
                    1911,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Description The Role We are looking for a qualified Data Engineer who will be part of the data engineering team. The ideal candidate will design and develop high quality data products - data warehouse, data marts, data lake data hubs and dashboards; either on cloud or on-premises system environments.  Responsibilities: Build and support the data pipeline and all the associated Software Engineering infrastructure tasks. Liaise with clients, technical architects, data architects, data scientists and BI analysts to gather the requirements. Analyse the data requirements, prepare the functional and non-functional specifications for the data products. Develop the data pipeline using either ETL/ELT approach to load or synchronise data in near real time or batch mode. Analyse and interpret data into business insights.   Design and develop the dashboards and visualizations using the BI tools. Ability to understand and convert the business logics into SQL queries and validate it against the data. Prepare the Test Plans and conduct Unit Testing, System Integration Test, User Acceptance Test and Performance Test. Implement the deployment approaches and methods to roll-out the system changes. Stay up to date with industry standards and technological advancements that will improve the quality of the data products. Requirements: Minimum bachelor\u2019s degree in Computer Science or related fields. At least 3 years of end-to-end data warehouse, data lake and big data implementation experience. Proficient with at least one or more of the following technologies: Informatica ETL Tools, SSIS, SQL Skills, SQL Server, Azure Data Factory, Data Warehouse, ETL Framework. Preferably possess a good knowledge about: Power BI, Qliksense, MicroStrategy, SAS and Tableau. Preferably possess a good knowledge about: DataStage, Attunity, Hadoop Ecosystem, Data APIs, Unstructured Data and Data Modelling. Manage and coach a team to achieve project objectives. Able to lead multiple teams and effectively work under pressure when there is an escalated demand in the project lifecycle. Understand the solution requirements and progress to design, develop, build and eventual operationalising the solutions. Enjoy problem solving in the different domains and industries. Love working with a highly energetic and competent team. A self-starter with an analytical approach to problem solving. A client-centric, outcome driven and quality focused team player. Excellent communication skills; both in written and spoken English. Additional Information Career Level Senior Executive Qualification Bachelor's Degree, Post Graduate Diploma, Professional Degree Years of Experience 3 years Job Type Full-Time Job Specializations Computer/Information Technology, IT-Software",
        {
            "entities": [
                [
                    960,
                    963,
                    "PROGLANG"
                ],
                [
                    1348,
                    1356,
                    "EDUCATION"
                ],
                [
                    1599,
                    1602,
                    "PROGLANG"
                ],
                [
                    1611,
                    1614,
                    "PROGLANG"
                ],
                [
                    1623,
                    1628,
                    "TOOL"
                ],
                [
                    1753,
                    1756,
                    "TOOL"
                ],
                [
                    1761,
                    1768,
                    "TOOL"
                ],
                [
                    1834,
                    1840,
                    "TOOL"
                ],
                [
                    2585,
                    2593,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Description Years of relevant working experience Minimum 3 years' of relevant experience Academic Requirement Bachelor/Master degree in Computer Science or related fields (or equivalent work-related experience) Key competencies Education in related fields (Computer Science, Computer Engineering, Mathematical Engineering, Information Systems) or job experience preferably within multiple Data Engineering technologies;  (3+ years of experience) Hands-on experience with one or more ETL tools like Informatica, Talend, Glue,  etc.  (3+ years of experience) Strong RDBMS concepts and SQL development skills  (2+ years of experience) Experience in preparing and reviewing new data flows patterns Knowledge of DataVault is a must  Good knowledge on NoSQL databases, such as Marklogic, HBase, Cassandra, MongoDB  Strong focus on data pipelines automation  Readiness to work with multiple tech domains and streams  Passionate about new technologies and experimentation  Experience in Python is a plus Key responsibilities Automate data flow processes  Supporting Data Analysts and Tech Leaders with evaluating data flow patterns  Close collaboration with Tech Leaders and Architects to achieve project goal  Explore new technologies and solutions  Working in agile environment in multidisciplinary team Mandatory skills Excellent command of English with outstanding communication skills  Experience in Pharmaceutical industry will be an added advantage. Working hours Normal hours with flexibility to participate in virtual meetings outside of core business hours Travel requirement Minimal Who we are At Roche, more than 100,000 people across 100 countries are pushing back the frontiers of healthcare. Working together, we've become one of the world's leading research-focused healthcare groups. Our success is built on innovation, curiosity and diversity. The Roche Services & Solutions as well as People Support Solutions organisations located in Kuala Lumpur provide end-to-end business solutions for Finance, Procurement, IT, Communications, People & Culture (Human Resources) and beyond to our Roche colleagues across the APAC region. Today Roche employs altogether around 1100 employees in Malaysia. Roche is an Equal Opportunity Employer. Job Level:  Manager without direct reports Additional Information Career Level Junior Executive Qualification Bachelor's Degree, Post Graduate Diploma, Professional Degree Job Type Full-Time Job Specializations Computer/Information Technology, IT-Network/Sys/DB Admin",
        {
            "entities": [
                [
                    114,
                    122,
                    "EDUCATION"
                ],
                [
                    123,
                    129,
                    "EDUCATION"
                ],
                [
                    515,
                    521,
                    "TOOL"
                ],
                [
                    587,
                    590,
                    "PROGLANG"
                ],
                [
                    793,
                    802,
                    "TOOL"
                ],
                [
                    804,
                    811,
                    "TOOL"
                ],
                [
                    983,
                    989,
                    "PROGLANG"
                ],
                [
                    2357,
                    2365,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Highlights Supportive of flexible working Remote working opportunity Profit Share, Employee Share Scheme, Free income protection Job Description About SEEK SEEK\u2019s portfolio of diverse businesses make a positive impact on a truly global scale. Our purpose is to help people live more fulfilling and productive working lives and help organisations succeed. We create world-class technology solutions to connect more people to relevant employment, education, small business and volunteer opportunities.  We have a culture of high-performance in our workplaces and celebrate the diversity of our employees who contribute to the success of our organisation.  Our Culture At SEEK we really value our culture and the way we work together to get stuff done. You will work amongst a group of hard-working, fun and caring people who will support you to have a successful and fulfilling career at SEEK. Our people are what make SEEK the company it is today and our dedication to fostering a work environment where people feel like they're making a difference every single day has meant people like to come here \u2013 and we're proud of that! We're honoured to be recognised as the Best Place to Work Overall and the #1 Best Place to Work - Tech Industry in The Australian Financial Review #BestPlaces2021 Awards. We wouldn't be where we are today without the SEEKers who make this company what it is. Job Description The Senior Data Engineer is a vital part of the Online Data Products Team, who provide trustworthy and safe to use data assets for SEEK teams across APAC, so that they can make informed decisions and deliver customer experiences using data. Responsibilities: Collaborate with internal customers, Data Warehouse Solution Designers, and the Data Platform team to translate requirements into technical solutions Grow the technical capabilities of more junior engineers through coaching and mentoring. Develop, test, and maintain: Data processing pipelines Datamarts and other data assets EMR/Spark/SQL jobs Deploy, operate, and support these in production using dev-ops principles Support consumers using our data assets (eg finding & understanding data, tuning queries, resolving data quality issues) Analyse and optimise performance of SQL queries, EMR/Spark jobs, physical schemas. The Team We are a distributed but close-knit team working from Melbourne and Kuala Lumpur with varied backgrounds and experiences, who work together to create great data products and services. We define our own ways of working and embrace flexible working arrangements. We manage our own roadmap in close consultation with our internal customers and align with Seek\u2019s long term strategy. We strive to bring equal parts passion and pragmatism to everything we do. Qualifications Significant experience developing data marts & warehouses Significant experience building and operating cloud-based data processing pipelines that are scalable, reliable, and performant Significant experience with data and databases: SQL coding, data modelling, data analysis, database development and performance optimisation Strong understanding of 'big data' technologies such as EMR/Hadoop, Spark, streaming technologies and MPP databases Ownership of deployments, monitoring, and operation of data pipelines in production (ie. DevOps) Growing the technical capabilities of more junior engineers through coaching and mentoring Perks and benefits At SEEK we offer: Employee Share Purchase Plan Support of flexible working Support for parents with 14 weeks paid primary carers leave Regular brown bag sessions covering a variety of topics Here at SEEK we pride ourselves on harbouring a flexible and inclusive working environment. Should you require any specific supports or adjustments throughout the recruitment process and beyond, please advise us and we will be happy to assist. Additional Information Career Level Senior Executive Qualification Diploma, Advanced/Higher/Graduate Diploma, Bachelor's Degree, Post Graduate Diploma, Professional Degree, Master's Degree Years of Experience 5 years Job Type Full-Time Job Specializations Computer/Information Technology, IT-Software",
        {
            "entities": [
                [
                    1995,
                    2000,
                    "TOOL"
                ],
                [
                    2001,
                    2004,
                    "PROGLANG"
                ],
                [
                    2241,
                    2244,
                    "PROGLANG"
                ],
                [
                    2258,
                    2263,
                    "TOOL"
                ],
                [
                    3000,
                    3003,
                    "PROGLANG"
                ],
                [
                    3153,
                    3159,
                    "TOOL"
                ],
                [
                    3161,
                    3166,
                    "TOOL"
                ],
                [
                    3961,
                    3969,
                    "EDUCATION"
                ],
                [
                    4024,
                    4030,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Description Responsible for development data integration with best practices and complying with the design provided by the technical lead. Develop ETL to ingest and transform data from databases and APIs into a data warehouse. Responsible for developing, supporting, as well as implementation of enterprise data warehouse and BI systems Assist in the maintenance and implementation of the ETL processes (SAS and SQL). Build and develop data pipelines to load, transform, and integrate data from various sources. Work on the ETL transformation configurations and resolve data integrity discrepancies. Work closely with the IT Teams and business users on setting up new data feeds and maintaining existing ones. Enhance and support the data warehouse batch processing. Participate in technical development life cycle including coding, testing, troubleshooting. Troubleshoot production support issues in ETL processes, data mining, data integration, and data quality issues. Perform user acceptance and system integration testing for quality assurance Job Requirements: A Bachelors degree or equivalent in information technology, Computer Science, Computer Engineering or equivalent.  1-2 years of experience in a technical role data engineering role or business intelligence development.  Strong programming, ETL and database management Skills i.e. SAS, SQL  Knowledge in .NET (VB) programming will be added advantage  Experience with data pipeline and workflow management  Able to work independently and in a team. Good critical thinking and problem-solving abilities  Ability to analyze and understand complex problems and explain technical information in business terms  Able to communicate clearly and effectively, both verbally and in writing Additional Information Career Level Junior Executive Qualification Diploma, Advanced/Higher/Graduate Diploma, Bachelor's Degree, Post Graduate Diploma, Professional Degree, Master's Degree Years of Experience 1 year Job Type Full-Time Job Specializations Computer/Information Technology, IT-Network/Sys/DB Admin",
        {
            "entities": [
                [
                    408,
                    411,
                    "PROGLANG"
                ],
                [
                    416,
                    419,
                    "PROGLANG"
                ],
                [
                    1351,
                    1354,
                    "TOOL"
                ],
                [
                    1356,
                    1359,
                    "PROGLANG"
                ],
                [
                    1860,
                    1868,
                    "EDUCATION"
                ],
                [
                    1923,
                    1929,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Description Competitive Salary Package Amazing Benefits and Growth Work Life Balance Career Progression about the company  Your future employer is a diverse group of companies, comprised of a strong portfolio of online employment, educational, commercial and volunteer businesses. The company has a global presence (including Australia, New Zealand, China, Hong Kong, South-East Asia, Brazil and Mexico) that provides amazing growth and exposure!  Job Description: As a Database Engineer you will be sought after for your broad spectrum of technical skills and experience covering various database platforms. You will contribute and support our APAC (Asia Pacific) Online database platforms as well as working to deliver modern technology implementations. You will be relied upon for your strong troubleshooting and ability, providing advice and looking for improvement opportunities This is a role for people who live and breathe the latest database technologies, thrive on uplifting and motivating those around them to higher levels of engagement, skillsets and experience and have a real passion for learning and developing. The role has a mix of both on-call support and opportunities to work on a varied program of project work that will suit someone comfortable working in a hybrid cloud environment. It will suit a person who has penchant for digging deep and attacking complex problems. Requirements 5+ years' experience in Enterprise Database Administration, Database Development/Engineering or Data Architecture/Engineering. Tertiary qualifications in a relevant discipline would be ideal Hands-on experience building, supporting and optimising relational database technologies such as MSSQL, MySQL or PostgreSQL Strong SQL development background and experience in one or more scripting languages Experience working with Windows Server & Linux operating systems Excellent facilitation and presentation skills, able to communicate to a wide audience, work collaboratively with openness and flexibility to deliver solutions quickly and efficiently Strong analytical and problem-solving abilities If you wish to know more or share the same passion, fun, energetic and would like to work in a progressive and forward thinking environment, kindly send your updated CV or reply to this email. I will reach out to you as soon as I can! *Please do note this position is only open for local Malaysians*  Winnie Tan | Randstad | winnie.tan@randstad.com.my Additional Information Career Level Non-Executive Qualification Diploma, Advanced/Higher/Graduate Diploma Job Type Full-Time Job Specializations Computer/Information Technology, IT-Network/Sys/DB Admin",
        {
            "entities": [
                [
                    1707,
                    1712,
                    "TOOL"
                ],
                [
                    1716,
                    1726,
                    "TOOL"
                ],
                [
                    1734,
                    1737,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "Job Description RESPONSIBILITIES Lead a team of ETL Developers to implement ETL systems that are operationally stable, efficient and automated. Design and implement scalable solutions which are aligned with the enterprise architecture and adaptable to business changes Monitor and optimize batch jobs, including automation and scheduling. Consistently review and enhance performance with key focus on ease of maintenance & jobs reusability Work with stakeholders from different business unit in reviewing business and technical requirements to offer Data Warehouse/Data Marts solutions to meet business needs Apply industry best practices for ETL design and development. Produce written deliverables for technical design system testing and implementation activities. Conduct System Testing - execute job flows, investigate system defects, resolve defects and document results. REQUIREMENTS 8-10 Years of IT experience, with 5+ years of experience in a related role such as Data Warehouse Developer, ETL, or Big Data Engineer working with large data sets. Strong experience with ETL and business intelligence tools, data warehouses, and in-memory solutions Familiar with Oracle technologies such as Business Intelligence (OBIEE), Oracle Data Integrator,  PL/SQL Working knowledge with Oracle, SQL Server, Unix Experience in leading a team of 5-10 person Excellent communication and collaboration skills If you are keen to be part of this exciting team, click Apply Now  for a confidential discussion Additional Information Career Level Senior Executive Qualification Bachelor's Degree, Post Graduate Diploma, Professional Degree Years of Experience 6 years Job Type Full-Time Job Specializations Computer/Information Technology, IT-Software",
        {
            "entities": [
                [
                    1170,
                    1176,
                    "TOOL"
                ],
                [
                    1229,
                    1235,
                    "TOOL"
                ],
                [
                    1254,
                    1260,
                    "PROGLANG"
                ],
                [
                    1284,
                    1290,
                    "TOOL"
                ],
                [
                    1292,
                    1295,
                    "PROGLANG"
                ],
                [
                    1566,
                    1574,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Description About airasia grocer Grocer is an e-commerce platform with three main verticals: (i) an online F&B supermarket (B2C) (ii) a F&B distributor and supplier to businesses (B2B) (iii) F&B exporter. Grocer is set to revolutionize the agribusiness supply chain by developing a good network of dark warehouse for efficient fulfillment and also connecting directly to farmers, eliminating middlemen costs. You will be joining a dynamic and fast-paced environment in a very exciting industry. If you\u2019ve always had a passion for food and for technology, and love to play and analyze data, do consider joining our Allstar family. What You'll Do: Create and maintain optimal data pipeline architecture Assemble large, complex data sets that meet functional / non-functional business requirements Ensure data integrity and quality Identify, design and implement internal process improvements; automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation and loading of data from a wide variety of data source using SQL and other technologies Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics Create data tools for analytics and data scientist team members to assist them in building and optimizing our business Leverage data visualization tools and techniques to maximize impact and value of data Provide support and work with cross-functional and multidisciplinary teams including the Management, Data Analytics, Product and Tech teams to assist with data-related technica issues and support their data infrastructure needs Manage external technical communication with the Group and Superapp team. Contribute to improving data governance policies. Keep up with current technical and industry developments. About You: BS/MS/PhD in a Business, IT, Mathematics, Science or Engineering discipline Minimum 5 yrs relevant experience beyond first degree Knowledge of programming languages like SQL, R, and Python Technical proficiency regarding database design development, data models, techniques for data mining and segmentation Experience in handling reporting package like Business objects, programming (Javascript, XML or ETL frameworks) databases Experience with code versioning, code review and documentation Experience with pipeline and workflow management tools Familiar with containerisation and orchestration tools Good working knowledge of productivity tools such as Big Query, DataStudio, Kubernetes and Tensorflow Knowledge of how to create and apply the most accurate algorithms to datasets in order to find solutions Proficient understanding of distributed computing principles Able to select and integrate big data tools and frameworks Problem solving skills and openness to experimenting with new techniques and new ways of working Team-working and able to operate under pressure and change, and balance among speed, reliability, interoperability Applicants with experience using Google Cloud Platform are highly favored. We are all different - one talent to another - that is how we rely on our differences. At AirAsia, you will be treated fairly and given all chances to be the best. We committed to creating a diverse work environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. Search Firm Representatives - AirAsia does not accept unsolicited assistance from search firms for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position-specific. Additional Information Career Level Senior Executive Qualification Bachelor's Degree, Post Graduate Diploma, Professional Degree, Master's Degree, Doctorate (PhD) Years of Experience 5 years Job Type Full-Time Job Specializations Computer/Information Technology, IT-Software",
        {
            "entities": [
                [
                    1142,
                    1145,
                    "PROGLANG"
                ],
                [
                    2142,
                    2145,
                    "PROGLANG"
                ],
                [
                    2147,
                    2148,
                    "PROGLANG"
                ],
                [
                    2154,
                    2160,
                    "PROGLANG"
                ],
                [
                    2650,
                    2660,
                    "TOOL"
                ],
                [
                    4292,
                    4300,
                    "EDUCATION"
                ],
                [
                    4355,
                    4361,
                    "EDUCATION"
                ],
                [
                    4372,
                    4381,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Description Are you ready to take off and be part of the Allstar employee? Whether you\u2019re applying for a developer, customer happiness or crew, at AirAsia we act as One AirAsia. If you are hungry to make a difference with one of the most well known low-cost airlines and to work in the dynamic technology hub, this is the job for you. AirAsia.com\u2019s data team drives conversion, personalisation, and revenue growth across flights and other lines of business. We are looking for Allstars to join an innovative and dynamic team which works in tandem with product and tech. You will help develop the future models and tools to drive better decisions and growth. What You\u2019ll Do: Ensures the data integrity and quality. Improve internal processes through automation, optimization, and re-design. Support and work with cross-functional and multidisciplinary teams in a dynamic environment. Leverage data visualization tools and techniques to maximize impact and value of data. Manage external technical communication with partners and vendors. Contribute to improving data governance policies. Keep current with technical and industry developments. About You: BS/MS/PhD in IT, Mathematics, Science or Engineering discipline Up to 8 yrs relevant experience beyond first degree Familiar with data ETL from a wide variety of data sources. Experience with SQL and NoSQL databases. Experience with pipeline and workflow management tools. Experience with various messaging and stream processing. Experience with object-oriented/object function scripting languages. Familiar with containerization and orchestration tools. Familiar with Google Cloud Platform and its tools and services. Ability to work under pressure and change, and balance among speed, reliability, interpretability. Good working knowledge of productivity tools such as G Suite, Git, Jira, Confluence. Experience with code versioning, code review and documentation. Proficient understanding of distributed computing principles. Able to select and integrate big data tools and frameworks. Familiar or prone to adopt design thinking methods. Openness to experimenting with new techniques and new ways of working. We are all different - one talent to another - that is how we rely on our differences. At AirAsia, you will be treated fairly and given all chances to be the best. We committed to creating a diverse work environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. Search Firm Representatives - AirAsia does not accept unsolicited assistance from search firms for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position-specific. Additional Information Career Level Senior Executive Qualification Professional Certificate, Bachelor's Degree, Post Graduate Diploma, Professional Degree, Master's Degree Years of Experience 8 years Job Type Full-Time Job Specializations Computer/Information Technology, IT-Software",
        {
            "entities": [
                [
                    1349,
                    1352,
                    "PROGLANG"
                ],
                [
                    1837,
                    1840,
                    "TOOL"
                ],
                [
                    1842,
                    1846,
                    "TOOL"
                ],
                [
                    3299,
                    3307,
                    "EDUCATION"
                ],
                [
                    3362,
                    3368,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Description Are you ready to take off and be part of the Allstar employee? Whether you\u2019re applying for a developer, customer happiness or crew, at AirAsia we act as One AirAsia. If you are hungry to make a difference with one of the most well known low-cost airlines and to work in the dynamic technology hub, this is the job for you. Mastering collaboration solutions for airline operations, Airline Data Department, a data business unit of Airasia, offers advanced data solutions for Flight Operations, Aircraft Maintenance and Data Infrastructure. The portfolio includes ML models, optimization solutions, data pipelines, professional apps, cloud infrastructures and associated services. We are proud to be one of the innovative teams of Airasia, the best budget airline provider in the world, scheduling domestic and international flights to more than 165 destinations spanning 25 countries. In doing so, we make a significant contribution to transform our airline into a tech-driven company. Duties and Responsibilities: Ensures the data integrity and quality. Develop, maintain and optimize data pipelines Work with stakeholders including the Executive, Product, Business and Analytic teams to assist with data-related issues and support their data transformation requirements. Manage external technical communication with partners and vendors. Contribute to improving data governance policies. Keep current with technical and industry developments. Requirements and Qualifications: BS/MS/PhD in Data Science, Computer Science, Mathematics, Science or Engineering discipline Up to 12 yrs relevant experience beyond first degree Ability to work under pressure and change, and balance among speed, reliability, interpretability. Proficient understanding of distributed computing principles. Able to select and integrate big data tools and frameworks. Familiar or prone to adopt design thinking methods. Openness to experimenting with new techniques and new ways of working. Ability to build internal clients relationships, and work effectively across functions and geographies. Ability to design solutions independently based on high-level architecture. Strong project management (waterfall, agile, scrum, etc) and organizational skills. Familiar with data extraction and transformation from a wide variety of data sources and formats. Experience with data pipeline and workflow management tools (Airflow). Experience with SQL and NoSQL databases. Experience with one of the following languages: Python, R, Java, C/C++ and Scala. Familiar with containerisation (Docker) and orchestration tools (Kubernetes). Familiar with one of the following cloud-based services: GCP, AWS or Azure. Good working knowledge of productivity tools such as G Suite, Git, Jira, Confluence. What makes an Allstar employee? You allow yourself to \u2018Dare to Dream\u2019 big dreams and seize the day. You \u2018Make things Happen\u2019, you like taking efforts and achieving it. Without any effort, no dream will get fulfilled. Our companies include Airasia.com, BigPay, Teleport, BigLife, RedBeat Ventures, AirAsia Foundation, Tune Group of Hotels, TuneProtect, OURSHOP, FORM.AT, Airasia Ads AirAsia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, gender, sexual orientation, national origin, disability or age. We are all different - one talent to another - that is how we rely on our differences. At AirAsia, you will be treated fairly and given all chances to be the best. We committed to creating a diverse work environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. Search Firm Representatives - AirAsia does not accept unsolicited assistance from search firms for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position-specific. Additional Information Career Level Manager Qualification Bachelor's Degree, Post Graduate Diploma, Professional Degree, Master's Degree, Doctorate (PhD) Years of Experience 12 years Job Type Full-Time Job Specializations Computer/Information Technology, IT-Software",
        {
            "entities": [
                [
                    2431,
                    2434,
                    "PROGLANG"
                ],
                [
                    2504,
                    2510,
                    "PROGLANG"
                ],
                [
                    2512,
                    2513,
                    "PROGLANG"
                ],
                [
                    2515,
                    2519,
                    "PROGLANG"
                ],
                [
                    2521,
                    2522,
                    "PROGLANG"
                ],
                [
                    2523,
                    2526,
                    "PROGLANG"
                ],
                [
                    2531,
                    2536,
                    "PROGLANG"
                ],
                [
                    2603,
                    2613,
                    "TOOL"
                ],
                [
                    2678,
                    2681,
                    "TOOL"
                ],
                [
                    2685,
                    2690,
                    "TOOL"
                ],
                [
                    2754,
                    2757,
                    "TOOL"
                ],
                [
                    2759,
                    2763,
                    "TOOL"
                ],
                [
                    4508,
                    4516,
                    "EDUCATION"
                ],
                [
                    4571,
                    4577,
                    "EDUCATION"
                ],
                [
                    4588,
                    4597,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Description Are you ready to take off and be part of the Allstar employee? Whether you\u2019re applying for a developer, customer happiness or crew, at AirAsia we act as One AirAsia. If you are hungry to make a difference with one of the most well known low-cost airlines and to work in the dynamic technology hub, this is the job for you. AirAsia.com\u2019s data team drives conversion, personalisation, and revenue growth across flights and other lines of business. We are looking for Allstars to join an innovative and dynamic team which works in tandem with product and tech. You will help develop the future models and tools to drive better decisions and growth. What You\u2019ll Do: Ensures the data integrity and quality. Improve internal processes through automation, optimization, and re-design. Support and work with cross-functional and multidisciplinary teams in a dynamic environment. Leverage data visualization tools and techniques to maximize impact and value of data. Manage external technical communication with partners and vendors. Contribute to improving data governance policies. Keep current with technical and industry developments. About You: BS/MS/PhD in IT, Mathematics, Science or Engineering discipline Up to 8 yrs relevant experience beyond first degree Familiar with data ETL from a wide variety of data sources. Experience with SQL and NoSQL databases. Experience with pipeline and workflow management tools. Experience with various messaging and stream processing. Experience with object-oriented/object function scripting languages. Familiar with containerization and orchestration tools. Familiar with Google Cloud Platform and its tools and services. Ability to work under pressure and change, and balance among speed, reliability, interpretability. Good working knowledge of productivity tools such as G Suite, Git, Jira, Confluence. Experience with code versioning, code review and documentation. Proficient understanding of distributed computing principles. Able to select and integrate big data tools and frameworks. Familiar or prone to adopt design thinking methods. Openness to experimenting with new techniques and new ways of working. We are all different - one talent to another - that is how we rely on our differences. At AirAsia, you will be treated fairly and given all chances to be the best. We committed to creating a diverse work environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. Search Firm Representatives - AirAsia does not accept unsolicited assistance from search firms for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position-specific. Additional Information Career Level Senior Executive Qualification Bachelor's Degree, Post Graduate Diploma, Professional Degree, Master's Degree, Doctorate (PhD) Years of Experience 8 years Job Type Full-Time Job Specializations Computer/Information Technology, IT-Software",
        {
            "entities": [
                [
                    1349,
                    1352,
                    "PROGLANG"
                ],
                [
                    1837,
                    1840,
                    "TOOL"
                ],
                [
                    1842,
                    1846,
                    "TOOL"
                ],
                [
                    3273,
                    3281,
                    "EDUCATION"
                ],
                [
                    3336,
                    3342,
                    "EDUCATION"
                ],
                [
                    3353,
                    3362,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Description Are you ready to take off and be part of the Allstar employee? Whether you\u2019re applying for a developer, customer happiness or crew, at AirAsia we act as One AirAsia. If you are hungry to make a difference with one of the most well known low-cost airlines and to work in the dynamic technology hub, this is the job for you. Group Data comes under AirAsia Digital which is responsible for spearheading digital transformation across AirAsia. Group Data works on business and operations problems across all entities in the AirAsia Group. Key problems we solve include improving revenue and reducing costs through large-scale data federation, predictive and prescriptive analytics, state-of-the-art machine/deep learning, intelligent scheduling and optimization, experimentation, and other advanced techniques. Group Data is also responsible for the data lakes across all our businesses, deriving insights and value from them and sharing them back with the businesses. In addition, Group Data also actively participates in innovation and training in the Redbeat Academy as well as collaboration with strategic partners like Google, GE, Airbus, and academia. What You\u2019ll Do: As a Lead Data Engineer, you are accountable for all the data pipelines and the overall quality of the data solutions that Experimentation platform supports. You will gather requirements and design solutions to support backstage website and APIs to power AirAsia\u2019s Experimentation and Optimisation platform. You will be responsible to support production code to produce comprehensive and accurate data artifacts. You will work with analysts, data scientists and software engineers and develop technical specifications for ETLs, including documentation. You will mentor and manage other engineers, guiding and ensuring the best practices are followed. You will guide communications between product managers and engineers to ensure they use the experimentation platform at its best. You will promote strategies to improve our data pipelines for collecting metrics for experiments and their statistical analysis. You got to have these to carryout the Job: Experience in developing microservices in golang(or any other language). Proficiency in writing SQL queries and knowledge of Massively Parallel Processing tools like Google Bigquery, Apache Spark, Trino. Experience with at least one of the programming languages like Python or Golang. Experience working with scheduling systems like Apache Airflow, Luigi, Argo e.t.c Experience with cloud infrastructure(Google Cloud, Kubernetes and Terraform). Experience working with Event Sourcing Systems. Summarize technical details to non-technical audiences. Hold yourself and others to a high bar when working with production systems Take pride in working on projects to successful completion involving a wide variety of technologies and systems You see yourself as part of the customer development team and have an opinion about how to improve the user experience and influence the direction of the product and the platform Thrive in a collaborative environment involving different stakeholders and subject matter experts Experience working with RESTful JSON APIs, cloud services, GitLab and you are proficient in Test Driven Development. Good working knowledge of productivity tools such as G Suite, Git, Jira, Confluence. Nice to have: You are a linux jedi. You have experience building full-stack applications (Golang, React, Typescript). You have experience with Continuous integration and delivery(CI/CD) like gitlab, github. You have experience with Business Intelligence tools like Metabase, Tableau, Superset. You have experience with A/B/n experimentation data pipelines. Knowledge of Networking and Infrastructure is a huge plus. About You: You have 5+ years of relevant experience and/or Bsc / Masters in Computer Science/Engineering You are great in Data Structure & algorithms, Aptitude and problem solving Good academic records Exceptional track record in delivering quality engineering solutions at different levels of the stack Strong experience with continuous integration, test automation, and monitoring Strong experience in application deployment and high availability Ability to work on a cross-functional team touching different parts of our core services We are all different - one talent to another - that is how we rely on our differences. At AirAsia, you will be treated fairly and given all chances to be the best. We committed to creating a diverse work environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. Search Firm Representatives - AirAsia does not accept unsolicited assistance from search firms for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position-specific. Additional Information Career Level Senior Executive Qualification Bachelor's Degree, Post Graduate Diploma, Professional Degree, Master's Degree Years of Experience 5 years Job Type Full-Time Job Specializations Computer/Information Technology, IT-Software",
        {
            "entities": [
                [
                    2234,
                    2237,
                    "PROGLANG"
                ],
                [
                    2328,
                    2333,
                    "TOOL"
                ],
                [
                    2405,
                    2411,
                    "PROGLANG"
                ],
                [
                    2556,
                    2566,
                    "TOOL"
                ],
                [
                    3331,
                    3334,
                    "TOOL"
                ],
                [
                    3336,
                    3340,
                    "TOOL"
                ],
                [
                    3629,
                    3636,
                    "TOOL"
                ],
                [
                    3829,
                    3832,
                    "EDUCATION"
                ],
                [
                    5412,
                    5420,
                    "EDUCATION"
                ],
                [
                    5475,
                    5481,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Description Company: AirAsia is Asia\u2019s largest low-cost carrier group with over 250 aircraft in operations, comprising of 9 separate airlines across 6 countries (and growing). At Teleport we are excited to transform the way air cargo and delivery is managed, sold, and transported in Southeast Asia. We are embracing technology and data at speed before it disrupts the industry, and us. As an operator transporting cargo to over >110 airports across Asia, we are at the frontlines of this large, but unsexy space. This white space motivates us to redefine the way the supply chain operates, expand our suite of services to get closer to the end customers and build products that empower both small business owners as well as large enterprises. We are looking for Full-Stack Data Engineer. You will be working with a team of 7-10 data-minded people \u2013 they will be your lifeline and your family during the day-to-day activities. This role will be on a full-time basis and you will be reporting daily to the Manager, Data Center of Excellence. Job Purpose: As a member of Teleport's Data Center of Excellence (CoE) responsible for helping to bridge the gap between business operations and data-driven insights. The Full-Stack Data Engineer role requires equal amounts of Business Operation Acumen, Software Engineering, and Data Management. Job Responsibilities: Create and maintain optimal data pipeline architecture Assemble large, complex data sets that meet functional / non-functional business requirements Ensure data integrity and quality Identify, design, and implement internal process improvements; automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and other technologies Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics Create data tools for analytics and data scientist team members to assist them in building and optimizing our business Leverage data visualization tools and techniques to maximize impact and value of data Provide support and work with cross-functional and multidisciplinary teams including the Management, Data, Product and Tech teams to assist with data-related technical issues and support their data infrastructure needs Manage external technical communication with various teams, and contribute to improving data governance policies. Keep up with current technology and industry developments. Job Requirments: BS/MS/Ph.D. in a Business, IT, Mathematics, Science or Engineering discipline Minimum 5 years of relevant experience beyond the first degree Knowledge of programming languages like SQL, R, and Python Technical proficiency regarding database design development, data models, techniques for data mining and segmentation Experience in handling reporting packages like Business objects, programming (Javascript, XML, or ETL frameworks) databases Experience with code versioning, code review, and documentation Experience with pipeline and workflow management tools Familiar with containerization and orchestration tools Good working knowledge of productivity tools such as Big Query, DataStudio, Kubernetes and Tensorflow Knowledge of how to create and apply the most accurate algorithms to datasets in order to find solutions Proficient understanding of distributed computing principles Able to select and integrate big data tools and frameworks Problem-solving skills and openness to experimenting with new techniques and new ways of working Team-working and able to operate under pressure and change, and balance among speed, reliability, interoperability To be proficient in Web Development using Go/NodeJs more than 4 years of experience Great in Data Structure & algorithms, Aptitude, and problem solving Have a deep respect for the challenges associated with operating a large-scale system in production, and designs and implementations reflect that understanding. Have a solid understanding of OOP REST architecture with experience in RESTful implementation Applicants with experience using Google Cloud Platform are highly favored. We are all different - one talent to another - that is how we rely on our differences. At AirAsia, you will be treated fairly and given all chances to be the best. We committed to creating a diverse work environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. Search Firm Representatives - AirAsia does not accept unsolicited assistance from search firms for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position-specific. Additional Information Career Level Senior Executive Qualification Bachelor's Degree, Post Graduate Diploma, Professional Degree, Master's Degree, Doctorate (PhD) Years of Experience 5 years Job Type Full-Time Job Specializations Computer/Information Technology, IT-Software",
        {
            "entities": [
                [
                    1154,
                    1157,
                    "PROGLANG"
                ],
                [
                    1859,
                    1862,
                    "PROGLANG"
                ],
                [
                    2859,
                    2862,
                    "PROGLANG"
                ],
                [
                    2864,
                    2865,
                    "PROGLANG"
                ],
                [
                    2871,
                    2877,
                    "PROGLANG"
                ],
                [
                    3370,
                    3380,
                    "TOOL"
                ],
                [
                    3875,
                    3877,
                    "PROGLANG"
                ],
                [
                    5419,
                    5427,
                    "EDUCATION"
                ],
                [
                    5482,
                    5488,
                    "EDUCATION"
                ],
                [
                    5499,
                    5508,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Description Company: AirAsia is Asia\u2019s largest low-cost carrier group with over 250 aircraft in operations, comprising of 9 separate airlines across 6 countries (and growing). At Teleport we are excited to transform the way air cargo and delivery is managed, sold, and transported in Southeast Asia. We are embracing technology and data at speed before it disrupts the industry, and us. As an operator transporting cargo to over >110 airports across Asia, we are at the frontlines of this large, but unsexy space. This white space motivates us to redefine the way the supply chain operates, expand our suite of services to get closer to the end customers, and build products that empower both small business owners as well as large enterprises. We are looking for Data Analyst Engineer. You will be working with a team of 7-10 data-minded people \u2013 they will be your lifeline and your family during the day-to-day activities. This role will be on a full-time basis and you will be reporting daily to the Manager, Data Center of Excellence. Job Purpose: As a member of Teleport's Data Center of Excellence (CoE) responsible for helping to bridge the gap between business operations and data-driven insights. The Data Analyst Engineer role requires equal amounts of Business Operation Acumen, Data Analysis, and Data Engineering . Job Responsibilities: Collaborate with team members to collect business requirements, define successful analytics outcomes, and design/create/maintain data models schemas. Collaborate and work across functional and multidisciplinary teams (including Data Scientists, Data Engineers, Software Developers, various stakeholders, etc.) in a dynamic environment to develop an understanding of evolving/agile business needs. Build trust in all interactions and with Trusted Data Development. Serve as the Directly Responsible Individual for major sections of the Enterprise Operation\u2019s Data Insights. Create and maintain architecture and systems documentation in the Data CoE Team Handbook. Maintain the Data Catalog, a scalable resource to support Self-Service and Single-Source-of-Truth Analytics. Implement the DataOps philosophy in everything you do. Develop data tools that enable manual process automation with the aim to improve productivity. Craft code that meets our internal standards for style, maintainability, and best practices (such as the SQL Style Guide) for a high-scale database environment. Maintain and advocate for these standards through code review. Approve data model changes as a reviewer and code owner for functional data model schemas. Job Requirements: Bachelor's Degree or higher from an accredited university preferably in the Business Information Systems, Computer Science, or Data Science programs. Positive and solution-oriented mindset. Comfort working in a highly agile, intensely iterative environment. Demonstrated capacity to clearly and concisely communicate complex business activities, technical requirements, and recommendations. 4+ years in the Data space as a data analyst, data engineer, or equivalent. 4+ years of industrial experience designing, implementing, operating, and extending analytical reports and dashboards. 2+ years working with a large-scale Data Warehouse, preferably in a cloud environment (GCP) in a commercial/production setting. 2+ years of industrial experience building reports and dashboards in a data visualization tool. 2+ years of industrial experience creating project plans to identify tasks, milestones, and deliverables Strong SQL/Python programming skills. Good understanding of statistics and probabilities. Familiar with BigQuery and Google Data Studio (Power BI and Tableau would be an advantage). We are all different - one talent to another - that is how we rely on our differences. At AirAsia, you will be treated fairly and given all chances to be the best. We committed to creating a diverse work environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. Search Firm Representatives - AirAsia does not accept unsolicited assistance from search firms for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position-specific. Additional Information Career Level Junior Executive Qualification Bachelor's Degree, Post Graduate Diploma, Professional Degree Years of Experience 4 years Job Type Full-Time Job Specializations Computer/Information Technology, IT-Network/Sys/DB Admin",
        {
            "entities": [
                [
                    1152,
                    1155,
                    "PROGLANG"
                ],
                [
                    2381,
                    2384,
                    "PROGLANG"
                ],
                [
                    2609,
                    2617,
                    "EDUCATION"
                ],
                [
                    3531,
                    3534,
                    "PROGLANG"
                ],
                [
                    3535,
                    3541,
                    "PROGLANG"
                ],
                [
                    3674,
                    3681,
                    "TOOL"
                ],
                [
                    4810,
                    4818,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Description Duties and Responsibilities: Responsible for meeting the needs of Data Engineering, Software Engineering and DevOps in the Customer Intelligence & Artificial Intelligence Team under Group Data at AirAsia. Takes charge of inputs and outputs of Data Scientists, and complement their skills & experience.  Data Engineering pipelines, data sourcing, ETL from a wide variety of data sources. Develop, package, transform & deploy the deliverables & outputs of Data Scientists (e.g. internal or POC-level dashboards, scripts, APIs, programs, reports, insights, codes, etc.), to become production-level secure, integrated, authenticated & well-maintained data products & services.  Act as bridges & strongly complement Data Scientists in the areas of data sources & pipelines, and data products & services, to accomplish various business use-cases and objectives. Highly skilled & experienced Individual Contributor track. Qualifications & Requirements: BS in Computer Science, Software Engineering, Computer Engineering, IT & related disciplines. At least 10 years of relevant full-time experience beyond first degree in Individual Contribution. Must have strong capability, discipline and passion to carry out full Individual Contribution. Must have successfully completed a lot of industry projects in both Data Engineering, and Software Engineering/Development/Deployments. Must be highly experienced in Google Cloud Platform (GCP) products and services (such as BigQuery, App Engine, Cloud Run, Cloud Functions, Cloud Firestore and Kubernetes Engine), Google Data Studio, Google Analytics, Google Marketing Platform, etc. Must be experienced in developing, integrating, deploying and maintaining data and software products, including containerisation, orchestration tools, Compute Engines, etc. Highly experienced in packaging outputs of Data Scientists\u2019 codes, scripts, projects, etc. (written in Python, C, C++, etc. on Windows, Linux, Mac, etc.), porting them whenever needed, developing data & software products & services around these outputs, and deploying them on GCP using barebone Compute Engines and/or cloud-managed tools & services. Well-versed in both back-end and front-end programming languages and frameworks such as Python (and its relevant libraries), JavaScript (and its frameworks and libraries), HTML and CSS, and experience with code versioning, code review, documentations, etc. Highly experienced in SQL and NoSQL databases, data pipelines and workflow management tools, various messaging and stream processing, data ETL, etc. Excellent with data structures (including trees & graph traversals), algorithms, time & space complexities to solve complex business problems using programming languages.  Good working knowledge of productivity tools such as G Suite, Git, Jira and Confluence. Have experience of test automation, creation of code repositories, creating and maintaining production-level APIs and microservices, framework orchestration, collaboration and workflow management, data preparation and integration. Experience in developing & deploying lots of large-scale projects using C, C++ & Python, embedding Python in C/C++, extending Python with C/C++, compilations, modifying, optimizing, and porting across different platforms, hardwares, Operating Systems, etc. is a plus. Participation & high rankings in national & international programming competitions is a plus. We are all different - one talent to another - that is how we rely on our differences. At AirAsia, you will be treated fairly and given all chances to be the best. We committed to creating a diverse work environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. Search Firm Representatives - AirAsia does not accept unsolicited assistance from search firms for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position-specific. Additional Information Career Level Manager Qualification Bachelor's Degree, Post Graduate Diploma, Professional Degree Years of Experience 10 years Job Type Full-Time Job Specializations Computer/Information Technology, IT-Software",
        {
            "entities": [
                [
                    1545,
                    1555,
                    "TOOL"
                ],
                [
                    1911,
                    1917,
                    "PROGLANG"
                ],
                [
                    1919,
                    1920,
                    "PROGLANG"
                ],
                [
                    1922,
                    1925,
                    "PROGLANG"
                ],
                [
                    2246,
                    2252,
                    "PROGLANG"
                ],
                [
                    2283,
                    2293,
                    "PROGLANG"
                ],
                [
                    2437,
                    2440,
                    "PROGLANG"
                ],
                [
                    2798,
                    2801,
                    "TOOL"
                ],
                [
                    2803,
                    2807,
                    "TOOL"
                ],
                [
                    3127,
                    3128,
                    "PROGLANG"
                ],
                [
                    3130,
                    3133,
                    "PROGLANG"
                ],
                [
                    3136,
                    3142,
                    "PROGLANG"
                ],
                [
                    3154,
                    3160,
                    "PROGLANG"
                ],
                [
                    3164,
                    3165,
                    "PROGLANG"
                ],
                [
                    3166,
                    3169,
                    "PROGLANG"
                ],
                [
                    3181,
                    3187,
                    "PROGLANG"
                ],
                [
                    3193,
                    3194,
                    "PROGLANG"
                ],
                [
                    3195,
                    3198,
                    "PROGLANG"
                ],
                [
                    4512,
                    4520,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Description Duration (months) : 12 months Location: Subang Hitech, Shah Alam Scope: Work closely with Business Analysts, SME's and end users to understand the requirements in order to determine feasibility. Designs technical solutions that are in line with business needs while staying consistent with application architecture. Navigate, understand, analyze and leverage existing complex data structures. Clarifies and resolves requirements questions. Coordinate with vendor to implement best practices and methodologies in mastering data management and in designing physical data models. Follows technical guidelines and best practices to ensure a consistently high standard of quality. Makes recommendations for next steps and long-term improvements. Investigate and troubleshoot data quality workflows or data quality issues or recurring technical problems. Analyze large databases and recommend appropriate optimization for the same Resolves defects or deficiencies with completed development, updates documentation, and provides training to support team members on completed development as necessary. Requirements: 8+ years of relevant experience in building and architecting data solutions. 3+ years of experience developing ETL process using SQL or tool like Talend, etc 2+ years of experience with Business Intelligence tools Expert in SQL and high-level languages such as Python or similar scripting language Experience with distributed data architectures and their eco-systems (Spark, EMR, Hadoop, Hive) Strong hands-on dimensional data modeling and data warehousing skills such as Microfocus Vertica preferable Experience in delivering data using Streaming Technologies (Kafka, Kinesis, Spark Streaming, etc.) Experience with continuous integration technologies (Jenkins, GitLab) Worked with Cloud-based architecture such as AWS Practical experience establishing and utilizing data analytics standard methodologies. Excellent organizational skills and detail-oriented. Exceptional teammate who establishes positive working relationships. Good communication skills with the ability to express sophisticated concepts effectively Preferable telco industry experience Preferable Skills/Tools: Talend Cloudera Data Hub \u2013 HBase, Impala, Kudu, Search, Spark, Spark Streaming, Hive on Spark, Cloudera Manager, Cloudera Director, and Cloudera Navigator Data Anonymization - Microfcus Voltage with Talend through API calls. Data Management \u2013 Cloudera Hadoop, Microfocus Vertica & AWS S3 Data Access & Reporting - Qlik Sense & Denodo Infrastructure \u2013 On Premise Redhat Virtualization and Cloud AWS OS \u2013 Linux and Window Job Types: Contract Contract length: 12 months Salary: RM6,000.00 - RM11,000.00 per month Benefits: Health insurance Schedule: Monday to Friday Ability to commute/relocate: Shah Alam: Reliably commute or planning to relocate before starting work (Preferred) Additional Information Career Level Senior Executive Qualification Bachelor's Degree, Post Graduate Diploma, Professional Degree Years of Experience 8 years Job Type Contract Job Specializations Computer/Information Technology, IT-Software",
        {
            "entities": [
                [
                    1253,
                    1256,
                    "PROGLANG"
                ],
                [
                    1270,
                    1276,
                    "TOOL"
                ],
                [
                    1348,
                    1351,
                    "PROGLANG"
                ],
                [
                    1385,
                    1391,
                    "PROGLANG"
                ],
                [
                    1492,
                    1497,
                    "TOOL"
                ],
                [
                    1504,
                    1510,
                    "TOOL"
                ],
                [
                    1702,
                    1707,
                    "TOOL"
                ],
                [
                    1778,
                    1785,
                    "TOOL"
                ],
                [
                    1840,
                    1843,
                    "TOOL"
                ],
                [
                    2204,
                    2210,
                    "TOOL"
                ],
                [
                    2260,
                    2265,
                    "TOOL"
                ],
                [
                    2267,
                    2272,
                    "TOOL"
                ],
                [
                    2292,
                    2297,
                    "TOOL"
                ],
                [
                    2403,
                    2409,
                    "TOOL"
                ],
                [
                    2456,
                    2462,
                    "TOOL"
                ],
                [
                    2485,
                    2488,
                    "TOOL"
                ],
                [
                    2489,
                    2491,
                    "PROGLANG"
                ],
                [
                    2518,
                    2522,
                    "TOOL"
                ],
                [
                    2598,
                    2601,
                    "TOOL"
                ],
                [
                    2949,
                    2957,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Description  Required Skills 1 or more years in Backend web application development 1 or more years in database administration Proficient in either PHP, Python, Ruby, NodeJS / Javascript Proficient in SQL (Mysql, PostgreSQL) or MongoDB Good knowledge in system administration for linux Experience in collaboration with team members in software development Knowledge in dealing with code repositories - git/Github/svn Good analytical capabilities & problem solving skills Good understanding of agile software development Well spoken English Responsibilities Understand and participate in the overall application development lifecycle On-going module development for full stack applications or backend microservices Break testing & creative bug fixing Provide valuable suggestions to improve products and workflows Additional Skills Familiar with AWS / GCP Familiar with Docker / Kubernetes / Vagrant Experience with integrating & creating API endpoints Experience with big data technologies & tools - Hadoop, Spark, Dbt Database administration Bonus to have worked with ML frameworks i.e Tensorflow, pyTorch Pragmatic in idea creation in brainstorming sessions, be open minded about constructive criticism & able to deal with rejection of ideas What You Will Learn Proper coding practices to refine your skills as a quality coder Basic SysAdmin skills to maintain a full stack system Continuous app deployment flows Benefits Travelling allowances Opportunity to build network with VCs & other tech entrepreneurs Employee training for relevant events - AWS/Google I/O etc. Experience Levels University / College undergraduates Certificates / Diploma on software development related disciplines Degree / Masters / PHD in Computer Science, Engineering or any software development related disciplines Additional Information Career Level Senior Executive Qualification Diploma, Advanced/Higher/Graduate Diploma, Bachelor's Degree, Post Graduate Diploma, Professional Degree Years of Experience 1 year Job Type Full-Time Job Specializations Computer/Information Technology, IT-Software",
        {
            "entities": [
                [
                    152,
                    155,
                    "PROGLANG"
                ],
                [
                    157,
                    163,
                    "PROGLANG"
                ],
                [
                    165,
                    169,
                    "PROGLANG"
                ],
                [
                    205,
                    208,
                    "PROGLANG"
                ],
                [
                    217,
                    227,
                    "TOOL"
                ],
                [
                    232,
                    239,
                    "TOOL"
                ],
                [
                    406,
                    409,
                    "TOOL"
                ],
                [
                    849,
                    852,
                    "TOOL"
                ],
                [
                    882,
                    892,
                    "TOOL"
                ],
                [
                    1004,
                    1010,
                    "TOOL"
                ],
                [
                    1012,
                    1017,
                    "TOOL"
                ],
                [
                    1555,
                    1558,
                    "TOOL"
                ],
                [
                    1715,
                    1718,
                    "EDUCATION"
                ],
                [
                    1910,
                    1918,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Description Job Description: Provide expertise for IT infrastructure (e.g. servers, network), application infrastructure (e.g. SAP), and related services (e.g. Business Continuity) throughout the lifecycle of a deal in accordance with contractually established terms and conditions and established technical standards. Provides technical input, solutions, and recommendations to deal pursuit. Engaged in and provides support for transition/transformation efforts. Monitors service delivery compliance to budget, quality standards, and customers and/or internal businesses/end user requirements. Provides IT infrastructure and/or application infrastructure lifecycle technical support, including planning, project management, installation, on-going management/monitoring/troubleshooting, and de-installation, following operational policies and processes that are compliant with industry standards (e.g. Information Technology Infrastructure Library (ITIL)). Manages the technical/service relationship between the company and the customer, and between the company and subcontractors/vendors. Works with the key customers and/or internal businesses/end user representatives (Infrastructure Support Managers, Client Manager and the Account Delivery Manager) to retain customers and build the business. ITO Service Delivery work is generally performed remotely from the company facility, but may be performed at the customer\u2019s location when required/justified. Responsibilities: Apply technical knowledge to operate a technology area (e.g. server administration, technical security management, performance management) or customer group with moderate risk/complexity. Integrates technical knowledge and business understanding to create superior solutions for the company and for customers. Incident Management: Resolve most technical incidents independently within your technical area. Work with team members to resolve more complex or cross-technology incidents. Escalation Management: identify potential escalations and alert management proactively. Problem Management: Begin to proactively and reactively provide solutions to prevent problems from occurring in area of responsibility. Change Management/Implementation: Independently reviews, implements, and verifies changes/solutions of moderate complexity and risk to meet customer and/or trade/IT infrastructure needs within area(s) of technical responsibility. Patch and Security Management: Apply patch and security changes per policy. Proactively monitor the environment for patch compliance. Configuration Management: Ensure Configuration Management Database (CMDB) entries are complete and accurate. Solution Design: Applies the company solutions to meet moderately complex customer and/or trade/IT infrastructure needs within area(s) of technical responsibility. Quality: Provide continual improvement recommendations/direction- setting advice within work team. Project Management: Participate in customer and internal projects, including transformation. Lead projects from own responsibility area. Customer Relationship Management: Balance internal needs with customers and/or internal businesses/end user's needs within defined parameters. Teamwork: Work as part of a team, which may be virtual, global, and/or multi-functional. Seen as a resource to the team within area of technical responsibility. Education and Experience Required: Bachelor's degree in Information Technology, Computer Science, Engineering, or related field or equivalent work experience. May hold entry-level or intermediate-level certification(s) in work field. Typically 0-3 years of relevant experience hence, fresh graduates are very welcome to apply. Knowledge and Skills: Typical skills include: Understanding of technology in direct responsibility (developing). General understanding of related technologies. Customer Service General Project Management (developing). Customer/Vendor Management (developing). Business Analysis (developing). General Financial Management . Additional Information Career Level Entry Level Qualification Bachelor's Degree, Post Graduate Diploma, Professional Degree Job Type Full-Time Job Specializations Computer/Information Technology, IT-Software",
        {
            "entities": [
                [
                    3398,
                    3406,
                    "EDUCATION"
                ],
                [
                    4074,
                    4082,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Are you a talented and driven problem solver who is eager to join our HQ in Kuala Lumpur? Someone with a startup mentality, who is capable of integrating into a multicultural team?  SOCAR aims to change the way people in South East Asia move around by becoming the biggest car-sharing platform in South East Asia. We are currently the biggest player in Malaysia and aim to scale out our product offering across more verticals and geographies.  We are growing fast - this is an extremely exciting time to join SOCAR.  Who are we looking for?  We are looking for an experienced Data Engineer to join our back-office ops squad that creates the technology ecosystem that enables SOCAR to support our ever-expanding user base while learning and delivering quickly.  We are looking for engineers that share our common interest in distributed backend systems, their scalability, and continued development. You will build highly distributed data pipeline systems that power our application while continuously improve our engineering practices.  Projects you will be working on? Build large-scale batch and real-time data pipelines with data processing frameworks like Spark and the Google Cloud Platform. Use best practices in continuous integration and delivery. Optimize our offerings for efficiency and reliability at scale Work in multi-functional agile teams to continuously experiment, iterate and deliver on new product objectives Identify areas of architectural improvement to make remove the potential for human error Collaborate with product and engineering teams to create innovative solutions to challenging problems Build out a testing framework to ensure uptime and reliability of data pipelines Understand the analytics data we collect from our systems and how it relates to the business value being produced Are you the ideal candidate?  First and foremost, ask yourself: Do you possess customer-fascination? This is SOCAR\u2019s prime value that drives our mission forward. If your heart and mind shout \u201cYES, I am!\u201d, you have just identified a fundamental match between you and your future SOCAR team. Possess excellent programming and software design skills. (We\u2019re primarily a Node shop, but are keen on looking at other languages for data related microservices, such as Go, Elixir etc.) Know how to work with high volume heterogeneous data, preferably with distributed systems such as Hadoop, Apache Beam, Spark. Know how to write distributed, high-volume data processing systems. Are knowledgeable about data modeling, data access, and data storage techniques. Love to be the bridge between engineering and analysis to have an impact on the product Interested in optimizing workflows and maintaining backend systems Appreciate agile software processes, data-driven development, reliability, and responsible experimentation. Understand the value of partnership within teams. Understand that product value is a function of usefulness and not technical implementation details. Preferred Technical Skills Experience with big data technologies such as Apache Beam, Spark, Hadoop. Experience in mapping or geospatial data pipelines a plus. Experience in designing and developing ETL data pipelines. Experience with Cassandra, Kafka is a plus. What we will offer you? Be part of the fastest-growing car-sharing company in the world! Opportunity to drive new ideas and make a measurable impact on company metrics Work with incredibly driven people with great executable ideas Competitive Salary Medical Insurance SOCAR travelling credits Phone allowance International environment (we are 10 different nationalities in the office!) The chance to launch new markets in different countries Endless company events (Futsal, cinema, birthday cakes, celebrations, team lunch and dinner ... ) How will your roadmap to join SOCAR look like?  After you submit your application, you can expect to prepare for the following steps in the hiring process: 1 video CV (Invitation to follow after your application is submitted) 1 session - Talent Acquisition Team (Virtual or face-to-face) 1 coding sample task (To be reviewed and presented in the technical round) 1 session - Technical round (Virtual or face-to-face) 1 session - CEO & CTO (Virtual or face-to-face) --  Follow us on LinkedIn  Check out our Homepage  Find us on Facebook",
        {
            "entities": [
                [
                    1160,
                    1165,
                    "TOOL"
                ],
                [
                    2277,
                    2279,
                    "PROGLANG"
                ],
                [
                    2281,
                    2287,
                    "PROGLANG"
                ],
                [
                    2392,
                    2398,
                    "TOOL"
                ],
                [
                    2413,
                    2418,
                    "TOOL"
                ],
                [
                    3068,
                    3073,
                    "TOOL"
                ],
                [
                    3075,
                    3081,
                    "TOOL"
                ],
                [
                    3217,
                    3226,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "We are Pulse iD  We are a Fintech Start-up that scales rapidly in the Asia Pacific region, currently operating out of Singapore (HQ), Malaysia, India, and Philippines.  We are an open Commerce platform for DeFi, FinTech, and banking. Businesses use our platform to manage and fund very targeted conversations with customers across banking channels, FinTechs, and cryptocurrency platforms. Integrations across payment networks allow us to embed intelligent promotions - with customers getting rewarded in FIAT or cryptocurrency.  What are we looking for?  We are looking for a Data Engineer that will help us discover and manage information hidden in vast amounts of data currently stored in our data lake, and help us take our next generation data driven products to the next level. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products with the key focus being ETL  Pulse iD is organized into small, agile, cross functional teams that work closely with the product and business development teams. Ownership is part of our DNA and every member of the team has a say in the shaping of the products they are working on.  Key Responsibilities Setting up ETL workflows within the data systems Analyze the collected data and suggest the addition of information that is relevant for building analytic systems Processing, cleansing, and verifying the integrity of data used for analysis Data mining using state-of-the-art methods Selecting features, building and optimizing classifiers using machine learning techniques Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems to help us improve our products and services  Experience and Qualifications At least 3 years experience in a relevant position Familiar with ETL tools within AWS Excellent understanding of supervised and unsupervised machine learning techniques and algorithms, such as k-NN, DBSCAN, PCA, Naive Bayes, SVM, Random Forests, etc Experience with common data science toolkits, such as SciPy, NumPy, Pandas, Scikit-learn, R, Weka, TensorFlow, etc. Excellence in at least one of these is highly desirable Experience with data visualisation tools, such as Matplotlib, Bokeh, Seaborn, GGplot, Plotly, D3.js, etc. Excellent proficiency in SQL Good applied statistics skills, such as regression modeling, statistical testing, etc Good scripting and programming skills in Python or Scala Strong presentation and communication skills, explaining complex analytical concepts to people from other fields  Nice to have Experience analyzing sensor and smartphone data Experience building data based products Worked extensively with Apache Spark Experience working with Apache Zeppelin University degree in a relevant field  Come work with us!  Check out our website www.pulseid.com for more information and stay engaged with us!",
        {
            "entities": [
                [
                    1890,
                    1893,
                    "TOOL"
                ],
                [
                    2126,
                    2132,
                    "LIBRARY"
                ],
                [
                    2148,
                    2149,
                    "PROGLANG"
                ],
                [
                    2151,
                    2155,
                    "TOOL"
                ],
                [
                    2157,
                    2167,
                    "LIBRARY"
                ],
                [
                    2280,
                    2290,
                    "LIBRARY"
                ],
                [
                    2292,
                    2297,
                    "LIBRARY"
                ],
                [
                    2299,
                    2306,
                    "LIBRARY"
                ],
                [
                    2316,
                    2322,
                    "LIBRARY"
                ],
                [
                    2361,
                    2364,
                    "PROGLANG"
                ],
                [
                    2492,
                    2498,
                    "PROGLANG"
                ],
                [
                    2502,
                    2507,
                    "PROGLANG"
                ],
                [
                    2754,
                    2759,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "\u201cThe future workforce is an equal one \u2013 we are setting the goal to achieve a gender balanced workforce by 2025. Find out more here.\u201d https://www.accenture.com/my-en/about/inclusion-diversity/gender-equality.  About Accenture  Accenture is a global professional services company with leading capabilities in digital, cloud and security. Combining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Interactive, Technology and Operations services\u2014all powered by the world\u2019s largest network of Advanced Technology and Intelligent Operations centres. Our 506,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. We embrace the power of change to create value and shared success for our clients, people, shareholders, partners and communities. Visit us at www.accenture.com.  Data Engineer  Responsibilities:  Work in interdisciplinary teams that combine technical, business and data science competencies.  Design and implement solutions around data warehouse implementation ranging from architecture, ETL processes, multidimensional modelling, data marts implementation.  Integrate datasets and dataflows using a variety of best in class software as well as profile and analyze large and complex datasets from disparate sources  Guide and direct junior developers  Shape and advise on detailed technical design decisions.  Develop scheduling scripts or configure load schedules  Design and run unit tests.  Perform bug diagnosis and fix.  Migrate code between development and test environments.  Participate in support of the development environment.  Qualifications:  1 + years designing and implementing large scale data loading, manipulation, processing solutions.  High proficiency in data integration package  High proficiency in Snowflake, Wherescape, ETL, Informatica, or Talend  Experience in streaming integration development  Cloud development experience (e.g. AWS, Azure)  Experience in implementing solutions using Hadoop/NoSQL technologies (e.g. HDFS, Hbase, Hive, Sqoop, Flume, Spark, MapReduce, Cassandra, MongoDB etc.)  Deep familiarity with RDBMS  Strong proficiency in SQL  Able to design and implement relational data models  Undergraduate degree at minimum in Comp Science/ Information Systems.  Professional Skills:  Eagerness to contribute in a team-oriented environment  Ability to work creatively and analytically in a problem-solving environment  Desire to work in an information systems environment  Excellent leadership, communication (written and oral) and interpersonal skills  You will also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.  Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.",
        {
            "entities": [
                [
                    1904,
                    1910,
                    "TOOL"
                ],
                [
                    1996,
                    1999,
                    "TOOL"
                ],
                [
                    2001,
                    2006,
                    "TOOL"
                ],
                [
                    2052,
                    2058,
                    "TOOL"
                ],
                [
                    2117,
                    2122,
                    "TOOL"
                ],
                [
                    2135,
                    2144,
                    "TOOL"
                ],
                [
                    2146,
                    2153,
                    "TOOL"
                ],
                [
                    2212,
                    2215,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "Job Description  Overview:  As an intern, you will provide technical, administrative, or operational support to the business within the Data Engineering and Advanced practice. This role offers the opportunity to work independently and make decisions with general supervision.  Internship Period: 1 Aug 22 to 20 Nov 22 (16 weeks)  Day-to-day, you will:  Work with interdisciplinary teams that combine technical, business, and data competencies  Contribute to design, build & deliver modern data platform which includes data architecture, data sourcing, data processing, data transformations, data storage, building/training ML models, data science algorithms, and BI reporting  Prepare platform for working on Machine learning projects, training, and deploying ML models  Support planning and implementation of data design services, providing sizing and configuration assistance, and performing needs assessments  Develop and maintain data warehouse schematics, layouts, architectures, and relational databases for data storage and data mining  Work with structured and unstructured data, no SQL databases for creating test and validation data sets for ML algorithms.  Work with annotation tools for annotating data for data science case studies  Deliver data to end-users using Microsoft Azure data services  Interpret and solve Data science challenges with Vision analytics, Natural language processing, Decision support systems  Perform exploratory Data analysis for solving machine learning problems  Work with Cloud computing platforms for Data Modernization, IoT and cloud AI services.  Work with DevOps for creating and maintaining source codes, deployment scripts, DevOps pipelines  Requirements:  Your skillset and likely experience include:  Undergraduates with minimally a STEM minor  Basic knowledge in data engineering / data science / machine learning  Exposure to cloud platforms and foundational cloud computing concepts.  Willingness to ramp up and be cross-functional across technologies.  Good coding acumen in any language, preferably python  Deep passion for technology with good logical thinking, analytical & problem-solving skills  Excellent verbal and written communication skills  Ability to excel in a team-oriented, project-based work environment  Previous work, internship, or co-op experience, preferably with customer-facing responsibilities  Ability to adapt and apply existing skills to new learning and technologies in a fast-paced environment  What we offer you  Come for the distinctive experiences you have helping forward-thinking corporations, non-profits, and governments push the boundaries of digital innovation. Stay for the limitless learning opportunities that encourage you to master Microsoft and pursue big ideas. Enjoy ambitious growth for yourself as part of Avanade\u2019s people-first culture with benefits like employee share purchasing, flexible work arrangements, a commitment to diversity and inclusion, and competitive pay.  About Avanade  Avanade is the leading provider of innovative digital, cloud and advisory services, industry solutions and design-led experiences across the Microsoft ecosystem. Every day, our 56,000 professionals in 26 countries make a genuine human impact for our clients, their employees and their customers.  We have been recognized as Microsoft\u2019s Global SI Partner of the Year more than any other company. With the most Microsoft certifications (60,000+) and 18 (out of 18) Gold-level Microsoft competencies, we are uniquely positioned to help businesses grow and solve their toughest challenges.  We are a people first company, committed to providing an inclusive workplace where employees feel comfortable being their authentic selves. As a responsible business, we are building a sustainable world and helping young people from underrepresented communities fulfil their potential.  Majority owned by Accenture, Avanade was founded in 2000 by Accenture LLP and Microsoft Corporation. Learn more at www.avanade.com .",
        {
            "entities": [
                [
                    1091,
                    1094,
                    "PROGLANG"
                ],
                [
                    1288,
                    1293,
                    "TOOL"
                ],
                [
                    2054,
                    2060,
                    "PROGLANG"
                ],
                [
                    2217,
                    2222,
                    "TOOL"
                ],
                [
                    2722,
                    2728,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Job Profile Summary Critical to achieving bp\u2019s digital ambitions is the delivery of our high value data and analytics initiatives, and the enablement of the technologies and platforms that will support those objectives.  As a Data Engineer you will be developing and maintaining data infrastructure and writing, deploying and maintaining software to build, integrate, manage, maintain, and quality-assure data at bp. You are passionate about planning and building compelling data products and services, in collaboration with business stakeholders, Data Managers, Data Scientists, Software Engineers and Architects in bp.  You will be part of bp\u2019s Data & Analytics Platform organisation, the group responsible for the platforms and services that operate bp\u2019s big data supply chain. The portfolio covers technologies that support the life cycle of critical data products in bp, bringing together data producers and consumers through enablement and industrial scale operations of data ingestion, processing, storage and publishing, including data visualisation, advanced analytics, data science and data discovery platforms.  For this role specifically, you will be in our data platform performance management team, focused on metrics and insights. This will involve designing and delivering the necessary data workflows and pipelines to collect and process data in order to provide visibility and insights to our platform operations and performance, including cost of operations, runtime and system analysis, continuous improvement opportunities, etc. The ultimate objective is to create a data-driven organisation within the Data & Analytics Platform team, and be able to build a \u2018mission control\u2019 station that will allow us to detect, anticipate and prevent issues, have insights to improve our operations, and have timely access to data that will allow our data platform engineers to build the necessary automation for a self-healing, etc. Further we want to exploit our data to understand non-technical measures and insights related to adoption and engagement, various measures of utilization, value contribution and delivery, quality assurance related to governance and compliance or identification of technical debt, and other scenarios that our leadership teams or platform engineers may challenge us on.  Job Advert Key Accountabilities Design, implement and maintain reliable and scalable data infrastructure, including design and development of industrial scale data pipelines to capture, store, process and publish platform telemetry for performance and utilisation analytics, and support the development and build the automation of system performance and metrics Collaboration with portfolio data platform teams to utilize existing data products, ingestion patterns, or automations to avoid bespoke development while contributing to the enhancement and creation of these shared assets when gaps are identified Own the end-to-end technical data lifecycle and corresponding data technology stack for their data domain and to have a deep understanding of the bp technology stack Write, deploy and maintain software to build, integrate, manage, maintain, and quality-assure data, and responsible for deploying secure and well-tested software that meets privacy and compliance requirements; develops, maintains and improves CI / CD pipeline Adhere to and advocate for software engineering best practices (e.g. technical design, technical design review, unit testing, monitoring & alerting, checking in code, code review, documentation) QUALIFICATIONS Deep and hands-on experience designing, planning, implementing, maintaining and documenting reliable and scalable data infrastructure and data products in complex environments Development experience in one or more object-oriented programming languages (e.g. Python, Go, Java, C++) Experience designing and implementing large-scale distributed system DESIRABLE CRITERIA Data Manipulation: debug and maintain the end-to-end data engineering lifecycle of the data products; design and implementation of the end-to-end data stack, including designing complex data systems, e.g. interoperability across cloud platforms; experience on various types of data (streaming, structured and un-structured) is a plus Coding: contribute to internal and/or external libraries through raising issues, adding documentation and/or contributing new features; write clean, re-usable code in a language that runs in production at bp Software Engineering: hands-on experience with SQL and NoSQL database fundamentals, query structures and design best practices, including scalability, readability, and reliability; you are proficient in at least one object-oriented programming language, e.g. Python [specifically data manipulation packages - Pandas, seaborn, matplotlib], Apache Spark or Scala; Scalability, Reliability, Maintenance: proven experience in building scalable and re-usable systems that are used by others; knowledge and experience in automating operations as much as possible and identifying and building for long-term productivity over short-term speed/gains, and execute on those opportunities to improve products or services Data Domain Knowledge: proven understanding of data sources and data and analytics requirements and typical SLAs associated to data provisioning and consumption at enterprise scale, with interest and experience in analysis of data or other enterprise platform operations activities Cloud Engineering\u2013 Recent experience utilizing data analytics offerings and services from Azure and AWS #bpDataAnalytics  #malaysiadataanlytics2021  Entity Innovation & Engineering  Job Family Group IT&S Group  Relocation available No  Travel Required No  Time Type Full time  Country Malaysia  About BP INNOVATION & ENGINEERING Join us in creating, growing, and delivering innovation at pace, enabling us to thrive while transitioning to a net zero world. All without compromising our operational risk management.  Working With Us, You Can Do This By deploying our integrated capability and standards in service of our net zero and safety ambitions driving our digital transformation and pioneering new business models collaborating to deliver competitive customer-focused energy solutions originating, scaling and commercialising innovative ideas, and creating ground-breaking new businesses from them protecting us by assuring management of our greatest physical and digital risks Because Together We Are Originators, builders, guardians and disruptors Engineers, technologists, scientists and entrepreneurs Empathetic, curious, creative and inclusive Experience Level Senior",
        {
            "entities": [
                [
                    3814,
                    3820,
                    "PROGLANG"
                ],
                [
                    3822,
                    3824,
                    "PROGLANG"
                ],
                [
                    3826,
                    3830,
                    "PROGLANG"
                ],
                [
                    3832,
                    3835,
                    "PROGLANG"
                ],
                [
                    4514,
                    4517,
                    "PROGLANG"
                ],
                [
                    4726,
                    4732,
                    "PROGLANG"
                ],
                [
                    4776,
                    4782,
                    "LIBRARY"
                ],
                [
                    4784,
                    4791,
                    "LIBRARY"
                ],
                [
                    4793,
                    4803,
                    "LIBRARY"
                ],
                [
                    4813,
                    4818,
                    "TOOL"
                ],
                [
                    4822,
                    4827,
                    "PROGLANG"
                ],
                [
                    5548,
                    5553,
                    "TOOL"
                ],
                [
                    5558,
                    5561,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "Job Profile Summary Responsible for supporting the delivery of business analysis and consulting processes and procedures for the defined specialism using sound technical capabilities, building and maintaining effective working relationships, ensuring relevant standards are defined and maintained, and supporting delivery of process and system improvements. Specialisms: Business Analysis; Data Management and Data Science; Digital Innovation.  Job Advert The Identity & Access Management (IAM) team are building a key data & analytics capability and service offering to provide analytical capabilities both internally and externally to consumers and customers of identity and access data. We are looking for a highly competent Data Analysts to help establish these services and to provide actionable, data-driven business insights by combining statistical skills, data manipulation capabilities and business acumen to achieve the desired outcomes.  Key Accountabilities The role will be part of the Identity & Access Management (IAM) portfolio within Enterprise & Operations (DE&O) and part of the IAM Data & Analytics team with accountability to: Work directly with the IAM Data & Analytics Staff Platform Engineer / Product Manager as part of the IAM Data & Analytics devops squad Proactively work with the team in IAM to define, gathering and articulate the business requirements to enable the translation into tangible analytical reports and visualisations to create data and analytics solutions in support of IAM analytics goals Work directly with the data through Azure Data Explorer, PowerBI or DataIKU to perform adhoc queries, data analysis and data discovery helping draw out insights from IAM data sets Be an active member of the devops team supporting agile practices and processes in the way work is delivered Helping prioritise backlogs across all IAM Data & Analytics products and features Facilitate the interface between the IAM customers and the Security Data Services (SDS) working closely with the Security Data Services (SDS) data lake team on delivery of use cases Work with the Security Data Services (SDS) to define and implement data schemas for the Identity & Access Management data domain Assist the team in data related queries/issues and address them in a timely fashion Contribute to the continuous improvement by supporting others in the team and improving the quality standards and efficiency of delivery Build awareness of internal and external technology developments Advocate and help ensure our architectures, designs and processes enhance a culture of operational safety and improve our digital security Key Requirements Preferably a Bachelor's (or higher) degree, preferably in Computer Science, MIS/IT, Mathematics or a hard science 10 years, with a minimum of at least 3 years\u2019 experience in Analytics / Data management. No prior experience in the energy industry required Ability to take initiative and work semi-autonomously to drive requirements and work delivery Experience with data analytics BI tools preferably Microsoft Power BI Ability to quickly develop appreciation for value that may be within data and able to guide teams on how to best draw out insights and value Good understanding of commonly available statistics approaches Able to write and maintain moderately complex data pipelines including scripting in R or python and good SQL skills Clear understanding of the end-to-end lifecycle of data Good understand of the application of data privacy and treatment of sensitive and personal data especially customer and consumer data Experience working as an agile team member and familiar with agile practices and processes A high Level of proficiency in Microsoft packages (Excel, PowerPoint etc) Good time management and organisation skills along with good communication skills Preferred Criteria / Skills: Experience working with identity & access management related data sets and IAM processes with awareness of related identity domains including consumer identity, identity protection and application access governance #bpDigitalEngineering  Entity Innovation & Engineering  Job Family Group IT&S Group  Relocation available No  Travel Required No  Country Malaysia  About BP INNOVATION & ENGINEERING Join us in creating, growing, and delivering innovation at pace, enabling us to thrive while transitioning to a net zero world. All without compromising our operational risk management.  Working With Us, You Can Do This By deploying our integrated capability and standards in service of our net zero and safety ambitions driving our digital transformation and pioneering new business models collaborating to deliver competitive customer-focused energy solutions originating, scaling and commercialising innovative ideas, and creating ground-breaking new businesses from them protecting us by assuring management of our greatest physical and digital risks Because Together We Are Originators, builders, guardians and disruptors Engineers, technologists, scientists and entrepreneurs Empathetic, curious, creative and inclusive Experience Level Intermediate  Legal disclaimer We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, sex, gender, gender expression, sexual orientation, age, marital status, neurodiversity/neurocognitive functioning, veteran status or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform crucial job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodations.",
        {
            "entities": [
                [
                    1571,
                    1576,
                    "TOOL"
                ],
                [
                    1592,
                    1599,
                    "TOOL"
                ],
                [
                    2672,
                    2680,
                    "EDUCATION"
                ],
                [
                    3366,
                    3367,
                    "PROGLANG"
                ],
                [
                    3371,
                    3377,
                    "PROGLANG"
                ],
                [
                    3387,
                    3390,
                    "PROGLANG"
                ],
                [
                    3730,
                    3735,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "Job Id: 22424585  The team is Analytics Innovation that is a global analytics unit under Global Internal Fraud Analytics. The team focuses on conducting the innovation and implementation of data pipeline, data structure, BigData Sandbox, detection routines, advanced algorithms, AI/ML models and Prevention Analytics. The current role is the team lead who reports to Internal Fraud Analytics Head directly.  Responsibility Under the supervision of global internal fraud innovation head, collaborate with a team of core data scientists based globally in advanced analytics innovation and implementation for all regions (APAC, EMEA, NAM and Mexico). Engage and work closely with each regional Internal Fraud Analytics Intelligence lead, support the timely and accurate delivery of sandbox implementation and simulation of all detective routines, as well as following up with regional technology development and support team on the testing and deployment of the routines in Production environment. Conduct advanced analytics/algorithm research and innovation, deliver AI/Machine Learning models for various use cases. Work closely with Internal Fraud Prevention team on the delivery of advanced dashboard. Work closely with Internal Fraud Governance and Control team on implementation and change process design, optimization, and execution. Qualifications 5-6 years of overall work experience 2+ years\u2019 experience in data engineering/Hadoop development/advanced analytics/modeling. Experience in fraud analytics or development is a plus. Understanding and hands-on experience of data engineering techniques and tools Spark, SQL, Python etc. Understanding and project experience of data management such as data pipeline, data structure and data quality governance. Understanding and project experience of AI and Machine Learning models is not a must but a plus. Proficient in Agile toolkits: Jira, Bitbucket and Confluence. Proficient in both spoken and written English. Education  Bachelor\u2019s degree/University degree or equivalent experience  -------------------------------------------------  Job Family Group:  Operations - Services  -------------------------------------------------  Job Family:  Fraud Operations  ------------------------------------------------------  Time Type:  Full time  ------------------------------------------------------  Citi is an equal opportunity and affirmative action employer.  Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.  Citigroup Inc. and its subsidiaries (\"Citi\u201d) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.  View the \"EEO is the Law\" poster. View the EEO is the Law Supplement.  View the EEO Policy Statement.  View the Pay Transparency Posting",
        {
            "entities": [
                [
                    1431,
                    1437,
                    "TOOL"
                ],
                [
                    1614,
                    1619,
                    "TOOL"
                ],
                [
                    1621,
                    1624,
                    "PROGLANG"
                ],
                [
                    1626,
                    1632,
                    "PROGLANG"
                ],
                [
                    1888,
                    1892,
                    "TOOL"
                ],
                [
                    1978,
                    1986,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "About the job  Tata Consultancy Services (TCS) is a global leader in IT services, digital, and business solutions that partners with its clients to simplify, strengthen, and transform their businesses. We ensure the highest levels of certainty and satisfaction through a deep-set commitment to our clients, comprehensive industry expertise, and a global network of innovation and delivery centers. For more information, visit us at www.tcs.com  Please find the job description below. Job Title: Data Engineer Location: Kuala Lumpur, Malaysia  Job Description: 1. Minimum 3 years of being in senior data engineer role 2. Experience in Data Transformation using ETL/ELT tools such as AWS Glue, Factory, Talend 3. Experience in database query using SQL Experienced in Cloud Data-related tool (Microsoft Azure, Amazon S3)  Thank you for your interest in applying for this position with TCS. We will review your application and will get back to you if we are considering your interest in this opportunity.",
        {
            "entities": [
                [
                    682,
                    685,
                    "TOOL"
                ],
                [
                    701,
                    707,
                    "TOOL"
                ],
                [
                    746,
                    749,
                    "PROGLANG"
                ],
                [
                    800,
                    805,
                    "TOOL"
                ],
                [
                    814,
                    816,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "Are you ready to get ahead in your career? We want to empower you turn your ambitions into achievements. We thrive in inclusiveness, diversity and embrace close collaborations for you to create impact for yourself and others. Together, we aim to bring the best of technology to help people, businesses and the nation to be ahead in a changing world. To realise our vision to become Malaysia\u2019s leading converged solutions company, we are looking for a new talent to innovate and grow with us in a culture that values commitment, performance and possibilities. Why does this job exist and why is it critical?  BI / Big Data Associate need to be the BI Data developers in the Big Data platform as well as stewards for data management governance and policies  What are you accountable for? Implement Business Intelligence applications. This includes designing, development, testing and deployment of the applications. Involved in innovation & creation of new Data Products & Data Solutions. Design, develop, test, and implement ETL/streaming process. Incorporate automated quality check and performance monitoring in DataOps manner. Advise necessary changes based on Data Platform related and open-sources technologies complimenting and enhancing DataOps process. Implement Business Intelligence or Data Platform's applications which includes designing, development, testing and deployment of the applications. Capture business or user requirements and perform system feasibility studies. Subject matter support on Data Platform applications to business users, business analysts and other department domains. Responsible for provide support in Data Governance , Master Data & Metadata Management Conduct users training on development and applications. Adhere and follow change management process and documentation as per company\u2019s standard. Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities. Experience with data warehouse design, build, deploy along with building real-time stream-processing systems, preferably using open-source solutions such as Storm or Spark-Streaming. What do you need to have for this role? Bachelors Degree Specialised in IT or related discipline For relative fresh graduate : need to have good recommendation and results related SQL, Phyton, Hadoop. For experienced professionals - Minimum of 3-5 years relevant working experience in Data Warehouse modelling and Datamarts development. Strong analytical and knowledge on ELT/ETL, data modelling and BI reporting tool is essential. Candidate with knowledge of Business Intelligence/Data Warehouse in Telecommunication environment and business background is preferable. Experience in GCP/BigQuery, Airflow, Warehouse technologies will be added advantage. Good team player, committed, able to work independently and under pressure to meet project timeline. Good communication skills in English both written and oral. Personal traits: Positive, Passionate, Collaborative, A self-starter, Ability to perform under pressure in a challenging environment and A team player What\u2019s next? Once you\u2019ve applied online, our team will carefully review your application. Due to a high volume of applications, we appreciate your patience to allow for a fair and timely review process. Should you be shortlisted for the role, we will send you an invitation via email for a digital interview. You can also check on your application status by logging into your candidate account. Maxis values diverse voices & people. We hire and reward our employees based on capability & performance \u2014 regardless of ethnicity, gender, age, education, religion, nationality or physical ability.",
        {
            "entities": [
                [
                    1658,
                    1664,
                    "EDUCATION"
                ],
                [
                    2107,
                    2112,
                    "TOOL"
                ],
                [
                    2304,
                    2307,
                    "PROGLANG"
                ],
                [
                    2317,
                    2323,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "Codes, tests, and debugs computer programs. Analyzes, designs and writes specifications for basic programs. Assists in identifying and resolving product problems with specific programs. Creates appropriate technical documentation. Performs data analysis.  Essential Job Functions Operations support of EDW data warehouse platform, provide availability of data and solve end-user reporting and accessibility problems. Monitor, control, and manage each incident arising from or relating to the services. Ensure Application services are restored in a timely manner. Support operations for multiple customers account with defined SLAs Ensure all operations reports are being monitored and act PROMPTLY within OPS SLA. Refreshing/Replacing data from production (PRO) to integration (ITG) for new coming projects. Analyzing errors occurred to spot common trends and underlying problems. Identifying contributing factors and causal factors of incidents. Work with other teams to fix errors and identify data problems. Participate in deployment to PRO & assist ETL Developer with deployment responsibilities. Assists users with questions or problems. Provide on-call support and participate in the shift roster. Demonstrate greater adaptability to changing priorities and flexible workloads. Proactively monitor the database systems to ensure minimum downtime. Responsible for deploying projects from DEV to ITG for testing purposes. Logging and keeping records of changes in the ITG and STG environments. Basic Qualifications Bachelor's degree in computer science, mathematics, or related field preferred 0 or 2 years of experience in programming or testing Experience working in a student employment program or related experience Experience working with appropriate programming languages, operating systems, and software Experience working with relational databases to facilitate programming software Other Qualifications Basic programming skills \u2013 desirable Python, Scala / .NET Analytical and problem-solving skills for design, creation, and testing of programs Interpersonal skills to interact with team members Communication skills to work effectively with team members, support personnel, and clients Work Environment Remote",
        {
            "entities": [
                [
                    1519,
                    1527,
                    "EDUCATION"
                ],
                [
                    1953,
                    1959,
                    "PROGLANG"
                ],
                [
                    1961,
                    1966,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "Company Description  The future. It\u2019s on you. You & Western Digital.  We\u2019ve been storing the world\u2019s data for more than 50 years. Once, it was the most important thing we could do for data. Now we\u2019re helping the world capture, preserve, access and transform data in a way only we can.  The most game-changing companies, consumers, professionals, and governments come to us for the technologies and solutions they need to capture, preserve, access, and transform their data.  But we can\u2019t do it alone. Today\u2019s exceptional data challenges require your exceptional skills. It\u2019s You & Us. Together, we\u2019re the next big thing in data.  Western Digital\u00ae data-centric solutions are found under the G-Technology\u2122, HGST, SanDisk\u00ae, Tegile\u2122, Upthere\u2122, and WD\u00ae brands.  Job Description  ESSENTIAL DUTIES AND RESPONSIBILITIES: Work with cross functional teams on data visualization. Deal with IT folks to setup data pipeline. Conduct advanced data analysis with machine learning (supervised & unsupervised) Explore, adopt, and introduce new data analytical method to the site and provide coaching to the relevant parties. Work with engineering on new approach in the machine learning to generate an appropriated algorithm to enable the artificial intelligent solution. Creates and sustains the report and tracking record on the development progression, updating the management or interested parties on timely basis. Provide technical support and training to the business domain or the beginner on data analytics and visualization. Promoting the data analysis culture in the organization and populate the uses of data visualization and big data application. Dealing with external service provider on new data analytical approach and relevant training. Consult the training department on the data analytic training syllabus. Qualifications  Qualifications Degree or Master\u2019s in Data Science or any equivalent certification or training, which proven with relevant skillset and knowledge. Required Minimum 3 years in data visualization development. Fresh graduates are encouraged to apply. Added advantages if working with machine learning, especially the transfer learning and AI development. Preferred Work in manufacturing environment or any relevant field. Skills Strong data analytical skill. Familiar with SQL and Python. Added advantage with other programming like Java, ASP.Net and C++ Other data analytical platform, such as Matlab (added advantage). Data visualization platform Spotfire (added advantage) or other platform. Additional Information  All your information will be kept confidential according to EEO guidelines.",
        {
            "entities": [
                [
                    1850,
                    1856,
                    "EDUCATION"
                ],
                [
                    2294,
                    2297,
                    "PROGLANG"
                ],
                [
                    2302,
                    2308,
                    "PROGLANG"
                ],
                [
                    2354,
                    2358,
                    "PROGLANG"
                ],
                [
                    2372,
                    2375,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "Our vision is to transform how the world uses information to enrich life for all.  Join an inclusive team passionate about one thing: using their expertise in the relentless pursuit of innovation for customers and partners. The solutions we build help make everything from virtual reality experiences to breakthroughs in neural networks possible. We do it all while committing to integrity, sustainability, and giving back to our communities. Because doing so can fuel the very innovation we are pursuing.  JR19757 Systems and Data Engineer  As a Process Engineer you will be primarily responsible for starting up, developing and optimizing processes to improve product quality and reliability, working on process yield improvement, cost reduction, productivity improvement and risk management as well as resolving manufacturing line problems. You will also be required to identify, diagnose and resolve assembly process related problems by applying failure analysis, FMEA, 8D or SPC/FDC methodology. Additional responsibilities include coordinating and carrying out process, equipment and material evaluation/optimization to implement changes at process step, leading and participating in yield improvement and cost reduction activities, handling new process baseline qualifications and managing, auditing and liaising with material suppliers to achieve quality, cost and risk management objectives.  Responsibilities Include, But Not Limited To  Work closely with Engineering, Manufacturing, IT, RMS, TSE, TAG, EDT, ToolView on systems setup and deployment that are critical for plant startup. Respond quickly to systems related issues, analyze, and resolve system failure mechanism through effective problem solving. Strong desire to grow career as data analyst /data scientist in highly automated industrial manufacturing doing analysis and machine learning on diverse datasets. Ability to extract data from different databases via SQL and other query languages, and apply data cleansing, outlier identification, and missing data techniques. Knowledge in statistical modeling, feature extraction, and analysis, machine learning, and deep learning. Strong coding skills on languages such as but not limited to Python and/or R, Perl, VB, C, JavaScript, Angular, Tableau. Experience in cloud computing and Hadoop is a plus. Strong desire to learn systems and data analytics / data science. Good verbal and written communication skills.  About Micron Technology, Inc.  We are an industry leader in innovative memory and storage solutions transforming how the world uses information to enrich life for all. With a relentless focus on our customers, technology leadership, and manufacturing and operational excellence, Micron delivers a rich portfolio of high-performance DRAM, NAND, and NOR memory and storage products through our Micron\u00ae and Crucial\u00ae brands. Every day, the innovations that our people create fuel the data economy, enabling advances in artificial intelligence and 5G applications that unleash opportunities \u2014 from the data center to the intelligent edge and across the client and mobile user experience.  Please note that in order to assist in providing a safe and healthy workplace for all Micron team members, new employment offers for jobs based in India, Malaysia, Singapore, and the U.S., are contingent upon the applicant\u2019s provision of a copy of their COVID-19 vaccination document to Micron on a confidential basis prior to their scheduled start date confirming that they have completed the COVID-19 vaccination process, subject to any written request for medical or religious accommodation and to the extent permitted by applicable law.  To learn more, please visit micron.com/careers  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.  To request assistance with the application process and/or for reasonable accommodations, please contact hrsupport_my@micron.com  Micron Prohibits the use of child labor and complies with all applicable laws, rules, regulations, and other international and industry labor standards.  Micron does not charge candidates any recruitment fees or unlawfully collect any other payment from candidates as consideration for their employment with Micron.",
        {
            "entities": [
                [
                    1936,
                    1939,
                    "PROGLANG"
                ],
                [
                    2213,
                    2219,
                    "PROGLANG"
                ],
                [
                    2227,
                    2228,
                    "PROGLANG"
                ],
                [
                    2230,
                    2234,
                    "PROGLANG"
                ],
                [
                    2240,
                    2241,
                    "PROGLANG"
                ],
                [
                    2243,
                    2253,
                    "PROGLANG"
                ],
                [
                    2264,
                    2271,
                    "TOOL"
                ],
                [
                    2307,
                    2313,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "About The Role  The Kuala Lumpur office is the technology powerhouse of MoneyLion. We pride ourselves on innovative initiatives and thrive in a fast paced and challenging environment. Join our multicultural team of visionaries and industry rebels in disrupting the traditional finance industry!  MoneyLion is building a world class data ecosystem that will dramatically improve the ability of internal data users and analysts to create products and experiences that captivate our customers. As the Data Engineer, you will participate in technical and architectural planning as well as contributing as a developer while interacting with data scientists, software engineers, and analysts as we build and scale the world's most rewarding program for financial wellness.  Key Responsibilities Assist with reviewing and interpreting business and technical requirements with a focus on data objectives of the product Identify requirements and develop data delivery solutions Implement company policies on data access and data distribution Support members of various teams to determine database structural requirements by analyzing their applications and client operations Collaborate with highly talented engineers while striving to help them build their skills and achieve their career goals Support data flow and ETL processes from end to end for projects and initiatives including troubleshooting of data issues, integrity checks, data model design, querying of data, and performance resulting from data issues Assist in training over the data systems used by the company for the employees. Specifically, training programs for new hires on various reports and models available in the data visualization tools that are used Analyze large data sets, some of them messy, to answer and solve real-world business problems while charting paths towards data cleanup and preventing data from becoming messy About You Familiarity with financial and banking products Demonstrated skills in good software engineering practices Building and shipping large-scale engineering products and/or infrastructure Scalable data architecture, fault-tolerant ETL, and monitoring data quality in the cloud (We use AWS) Collaborating with a diverse set of engineers, data scientists and product managers Deep expertise in data engineering and data processing at scale. Requires a focus on the development of pipelines for the creation of data lakes to enable exploration as well as machine learning model training, deployment and scoring at massive scale. Familiarity with data science techniques and frameworks NoSQL, Relational databases and Presto (We use MongoDB, MySQL, PostgreSQL, ElasticSearch) The AWS stack combined with technologies such as Java, Python, Spark, and Kafka Familiarity with Apache Airflow or equivalent workflow management tools What's Next...  After you submit your application, you can expect the following steps in the recruitment process: Interview - Talent Acquisition Team (Virtual or face-to-face) Sample test - To be discussed in the technical round Interview - Hiring Manager (Virtual or face-to-face) What We Value  We value growth-minded and collaborative people with high learning agility who embody our core values of teamwork, customer-first and innovation. Every member of the MoneyLion Pride is passionate about fintech and ready to give 100% in helping us achieve our mission..  Working At MoneyLion  At MoneyLion, we want you to be well and thrive. Our generous benefits package includes: Competitive salary packages and bonuses Comprehensive medical, dental, vision and life insurance benefits Equity based compensation Wellness perks Paid parental leave Unlimited Paid Time Off Learning and Development resources Flexible working hours MoneyLion is committed to equal employment opportunities for all employees. Inside our company, every decision we make regarding our employees is based on merit, competence, and performance, completely free of discrimination. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. Within that team, no one will feel more \u201cother\u201d than anyone else. We realize the full promise of diversity and want you to bring your whole self to work every single day.",
        {
            "entities": [
                [
                    58,
                    68,
                    "PROGLANG"
                ],
                [
                    2187,
                    2190,
                    "TOOL"
                ],
                [
                    2616,
                    2622,
                    "TOOL"
                ],
                [
                    2631,
                    2638,
                    "TOOL"
                ],
                [
                    2640,
                    2645,
                    "TOOL"
                ],
                [
                    2647,
                    2657,
                    "TOOL"
                ],
                [
                    2659,
                    2672,
                    "TOOL"
                ],
                [
                    2678,
                    2681,
                    "TOOL"
                ],
                [
                    2723,
                    2727,
                    "PROGLANG"
                ],
                [
                    2729,
                    2735,
                    "PROGLANG"
                ],
                [
                    2737,
                    2742,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "Open Position: Data Engineer (Tech-based Company)  A Tech-based Company is looking for an enthusiastic and self-motivated Data Engineer who will ensure the smooth operation of a high volume data pipeline solutions and architecture. You will be working closely in a cross-functional environment, collaborating with Data Scientists, Product Managers, Engineering Teams and Business Stakeholders, providing the organization with analytical data.  Key Requirements Include Bachelor\u2019s degree or higher in an applicable field such as Computer Science, Statistics, Maths or similar Science or Engineering discipline Strong knowledge of SQL databases and strong coding skills with Python and data Cleansing In-depth knowledge of the Hadoop ecosystem, its various components, along with different tools including ETL, Spark, Hive, and Pig along with Python Experience using noSQL databases such as MongoDB and JSON Experience deploying and using cloud based data analytics visualization tools such as Looker, D3.js Proficient in data wrangling and preparation using Python, SQL, Spark and experience in working large data sets Validated analytical and problem-solving skills and implementing them in Big Data Experience worked in an agile environment If you are interested, please send your updated CV to shuba@btcrecruitment.com for a confidential discussion.  Only shortlisted candidate will be notified.  Visit us at www.btcrecruitment.com today.  #dataengineer #bigdata #hadoop #etl #python #datajobs #techjobs #career #jobseekers #jobopportunity #btcmalaysia #btcrecruitment",
        {
            "entities": [
                [
                    469,
                    477,
                    "EDUCATION"
                ],
                [
                    629,
                    632,
                    "PROGLANG"
                ],
                [
                    673,
                    679,
                    "PROGLANG"
                ],
                [
                    725,
                    731,
                    "TOOL"
                ],
                [
                    809,
                    814,
                    "TOOL"
                ],
                [
                    841,
                    847,
                    "PROGLANG"
                ],
                [
                    889,
                    896,
                    "TOOL"
                ],
                [
                    1057,
                    1063,
                    "PROGLANG"
                ],
                [
                    1065,
                    1068,
                    "PROGLANG"
                ],
                [
                    1070,
                    1075,
                    "TOOL"
                ],
                [
                    1466,
                    1472,
                    "TOOL"
                ],
                [
                    1479,
                    1485,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "\u201cThe future workforce is an equal one \u2013 we are setting the goal to achieve a gender balanced workforce by 2025. Find out more here.\u201d https://www.accenture.com/my-en/about/inclusion-diversity/gender-equality. About Accenture Accenture is a global professional services company with leading capabilities in digital, cloud and security. Combining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Interactive, Technology and Operations services\u2014all powered by the world\u2019s largest network of Advanced Technology and Intelligent Operations centres. Our 506,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. We embrace the power of change to create value and shared success for our clients, people, shareholders, partners and communities. Visit us at www.accenture.com. Data Engineer Responsibilities: Work in interdisciplinary teams that combine technical, business and data science competencies. Design and implement solutions around data warehouse implementation ranging from architecture, ETL processes, multidimensional modelling, data marts implementation. Integrate datasets and dataflows using a variety of best in class software as well as profile and analyze large and complex datasets from disparate sources Guide and direct junior developers Shape and advise on detailed technical design decisions. Develop scheduling scripts or configure load schedules Design and run unit tests. Perform bug diagnosis and fix. Migrate code between development and test environments. Participate in support of the development environment. Qualifications: 4 + years designing and implementing large scale data loading, manipulation, processing solutions. High proficiency in data integration package High proficiency in Snowflake, Wherescape, ETL, Informatica, or Talend Experience in streaming integration development Cloud development experience (e.g. AWS, Azure) Experience in implementing solutions using Hadoop/NoSQL technologies (e.g. HDFS, Hbase, Hive, Sqoop, Flume, Spark, MapReduce, Cassandra, MongoDB etc.) Deep familiarity with RDBMS Strong proficiency in SQL Able to design and implement relational data models Undergraduate degree at minimum in Comp Science/ Information Systems. Professional Skills: Eagerness to contribute in a team-oriented environment Ability to work creatively and analytically in a problem-solving environment Desire to work in an information systems environment Excellent leadership, communication (written and oral) and interpersonal skills You will also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career. Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.",
        {
            "entities": [
                [
                    1886,
                    1892,
                    "TOOL"
                ],
                [
                    1976,
                    1979,
                    "TOOL"
                ],
                [
                    1981,
                    1986,
                    "TOOL"
                ],
                [
                    2031,
                    2037,
                    "TOOL"
                ],
                [
                    2096,
                    2101,
                    "TOOL"
                ],
                [
                    2114,
                    2123,
                    "TOOL"
                ],
                [
                    2125,
                    2132,
                    "TOOL"
                ],
                [
                    2189,
                    2192,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "Company Description  At Western Digital, our vision is to power global innovation and push the boundaries of technology to make what you thought was once impossible, possible.  At our core, Western Digital is a company of problem solvers. People achieve extraordinary things given the right technology. For decades, we\u2019ve been doing just that. Our technology helped people put a man on the moon.  We are a key partner to some of the largest and highest growth organizations in the world. From energizing the most competitive gaming platforms, to enabling systems to make cities safer and cars smarter and more connected, to powering the data centers behind many of the world\u2019s biggest companies and public cloud, Western Digital is fueling a brighter, smarter future.  Binge-watch any shows, use social media or shop online lately? You\u2019ll find Western Digital supporting the storage infrastructure behind many of these platforms. And, that flash memory card that captures and preserves your most precious moments? That\u2019s us, too.  We offer an expansive portfolio of technologies, storage devices and platforms for business and consumers alike. Our data-centric solutions are comprised of the Western Digital\u00ae, G-Technology\u2122, SanDisk\u00ae and WD\u00ae brands.  Today\u2019s exceptional challenges require your unique skills. It\u2019s You & Western Digital. Together, we\u2019re the next BIG thing in data.  Job Description Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and data cloud \u2018big data\u2019 technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders including the Operations, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and data cloud. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. Qualifications Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing \u2018big data\u2019 data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable \u2018big data\u2019 data stores. Strong project management and organizational skills. Experience supporting and working with cross-functional teams in a dynamic environment. We are looking for a candidate with 1-2 years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools: Experience with big data tools: Hadoop, etc. Experience with relational SQL and NoSQL databases Experience with data cloud services: Redshift Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc. Additional Information  Western Digital thrives on the power and potential of diversity. As a global company, we believe the most effective way to embrace the diversity of our customers and communities is to mirror it from within. We believe the fusion of various perspectives results in the best outcomes for our employees, our company, our customers, and the world around us. We are committed to an inclusive environment where every individual can thrive through a sense of belonging, respect and contribution.  Western Digital is committed to offering opportunities to applicants with disabilities and ensuring all candidates can successfully navigate our careers website and our hiring process. Please contact us at staffingsupport@wdc.com to advise us of your accommodation request. In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying.",
        {
            "entities": [
                [
                    1862,
                    1865,
                    "PROGLANG"
                ],
                [
                    2644,
                    2647,
                    "PROGLANG"
                ],
                [
                    2725,
                    2728,
                    "PROGLANG"
                ],
                [
                    3894,
                    3900,
                    "TOOL"
                ],
                [
                    3934,
                    3937,
                    "PROGLANG"
                ],
                [
                    4073,
                    4079,
                    "PROGLANG"
                ],
                [
                    4081,
                    4085,
                    "PROGLANG"
                ],
                [
                    4087,
                    4090,
                    "PROGLANG"
                ],
                [
                    4092,
                    4097,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "Sarawak, Malaysia  Job Family Group  Information Technology (IT)  Worker Type  Regular  Posting Start Date  April 11, 2022  Business Unit  Experience Level:  Experienced Professionals  Job Description  If you are an analytical thinker with passion in crunching data this could be your opportunity to transform, aggregate messy data and unlock the full data potential of data to deliver value through business insights. You will have an opportunity to grow your career in a core Upstream country that continues to deliver on growth, ensuring that our product line remains carbon resilient through the development of new value chain businesses in Malaysia.  Where you fit in  The Data Engineer is responsible for identifying relevant data to be gathered and implementing a solution to do so, including knowledge of where to get the data, how to extract it in the right format, and how to augment the data to support data science/analysis requirements. Able to build a robust, fault-tolerant data pipeline that cleans, transforms, and aggregates un-organised and messy data into databases or data sources. Able to ensure that data flows smoothly from source to destination so that it can be processed.  What\u2019s the role?  The Data Engineer is an expert in SQL development support to the data and analytics IT experts in database design, data flow and data analysis activities. The Data Engineer plays a key role in the development and deployment of innovative big data platforms for advanced analytics and data processing.  The Data Engineer defines and builds the data pipelines that will enable faster, better, data-informed decision-making within the business.  Deep experience in developing enterprise data management strategies including operational data stores, data warehouse implementations, data movement, data services, data acquisition, data conversion, and archive/recovery.  Accountabilities Work together with the Solution and Data Architect to design the next generation big data platform to support the digital twin or surface engineering data platform. Design and implement a new big data solution which supports high amounts- and velocity of data, supports future growth, use latest big data technologies/techniques, is cloud supported and in-line with Shell\u2019s strategies. Design and implement modern data pipelines to extract, clean and process data in batch and real-time from different data sources. Use the latest development, testing and deployment techniques to quickly deploy new releases to e.g. deploy new data pipelines and add data sources. Help establish best practices around data governance, data security and privacy (GDPR). Work together with the solution and data architect to the define the target data strategy. Drives and applies Agile Framework within his/her operating environment. Will take direct reports, when applicable, through Agile Framework and its respective tools. What we need from you?  We are keen to hear from professionals with the following experiences: Bachelor or master degree in information technology, computer science, business administration or a related discipline. Certified in Agile Product Owner / SCRUM master and/or other Agile techniques Interpretation of data, highly analytical, troubleshooting and problem-solving skills. Experience with data architecture and design techniques (local/abstract). Experience with API techniques/developments. Experience with SQL-based technologies (e.g. MSSQL, MySQL, PostgreSQL). Experience with data transformation/blending technology (e.g. Alteryx is preferred). Experience with working concepts as data pipelining / data wrangling Experience with big data platforms; working with large data sets, large amounts of data in motion and numerous big data technologies. Agile Project Delivery techniques (e.g. SCRUM) & experience creating and using a wide range of scrum and agile artefacts and techniques, automated testing, personas, user stories, agile games etc Awareness of Agile Framework and its tools such as Visual Studio Team Services (VSTS) Disclaimer  Please note: We occasionally amend or withdraw Shell jobs and reserve the right to do so at any time, including prior to the advertised closing date. Before applying, you are advised to read our data protection policy. This policy describes the processing that may be associated with your personal data and informs you that your personal data may be transferred to Royal Dutch/Shell Group companies around the world. The Shell Group and its approved recruitment consultants will never ask you for a fee to process or consider your application for a career with Shell. Anyone who demands such a fee is not an authorised Shell representative and you are strongly advised to refuse any such demand. Shell is an Equal Opportunity Employer.",
        {
            "entities": [
                [
                    1252,
                    1255,
                    "PROGLANG"
                ],
                [
                    3006,
                    3014,
                    "EDUCATION"
                ],
                [
                    3018,
                    3024,
                    "EDUCATION"
                ],
                [
                    3167,
                    3173,
                    "EDUCATION"
                ],
                [
                    3426,
                    3429,
                    "PROGLANG"
                ],
                [
                    3462,
                    3467,
                    "TOOL"
                ],
                [
                    3469,
                    3479,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and data cloud \u2018big data\u2019 technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders including the Operations, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and data cloud. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems.  Qualifications  Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing \u2018big data\u2019 data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable \u2018big data\u2019 data stores. Strong project management and organizational skills. Experience supporting and working with cross-functional teams in a dynamic environment. We are looking for a candidate with 1-2 years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools: Experience with big data tools: Hadoop, etc. Experience with relational SQL and NoSQL databases Experience with data cloud services: Redshift Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.  Additional Information  Western Digital thrives on the power and potential of diversity. As a global company, we believe the most effective way to embrace the diversity of our customers and communities is to mirror it from within. We believe the fusion of various perspectives results in the best outcomes for our employees, our company, our customers, and the world around us. We are committed to an inclusive environment where every individual can thrive through a sense of belonging, respect and contribution.  Western Digital is committed to offering opportunities to applicants with disabilities and ensuring all candidates can successfully navigate our careers website and our hiring process. Please contact us at staffingsupport@wdc.com to advise us of your accommodation request. In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying.",
        {
            "entities": [
                [
                    463,
                    466,
                    "PROGLANG"
                ],
                [
                    1247,
                    1250,
                    "PROGLANG"
                ],
                [
                    1328,
                    1331,
                    "PROGLANG"
                ],
                [
                    2497,
                    2503,
                    "TOOL"
                ],
                [
                    2537,
                    2540,
                    "PROGLANG"
                ],
                [
                    2676,
                    2682,
                    "PROGLANG"
                ],
                [
                    2684,
                    2688,
                    "PROGLANG"
                ],
                [
                    2690,
                    2693,
                    "PROGLANG"
                ],
                [
                    2695,
                    2700,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "Are you a Senior Storage Engineer looking for a new challenge?  Do you like working in collaborative teams and solving technical problems?  Join our Digital Technology Team  We operate at the heart of the digital transformation of our business. Our team is responsible for design, support, and maintenance for data protection and storage across our global organization. From digital engineering to enabling employee success, the Digital Technology team provides premium products and services to our customers and employees.  Partner with the best  As a Senior Systems Data Protection and Storage Engineer, you're responsible for design, support, and maintenance for Digital Technology Team. You'll be involved in aspects of storage infrastructure availability (lifecycle and uptime), storage management and data durability.  As a Senior Systems Data Protection and Storage Engineer, you will be responsible for:  Configurating, allocating, and managing centralized storage systems and other deployed storage solutions Helping to develop or engineer new solutions related to data storage and access Helping architect data protection solutions based on company strategy Implementing new storage technologies - tapeless, cloud storage etc. Automating processes and overall selection of data protection methodologies Updating any obsolete sections of the data storage, management, and access network Keeping records of upgrades and proposed system upgrades that will streamline data handling Partnering with the Cyber Security Risk and Compliance organization to ensure appropriate handling of data storage and resolution of audit findings  Fuel your passion  To be successful in this role you will:  Have experience using Veeam Backup and Replication software in an enterprise type environment Have experience with AWS and/or Azure cloud platform Have bachelor's Degree in Computer Science or in a \u201cSTEM\u201d Major (Science, Technology, Engineering, and Math) from an accredited college or university (OR High School Diploma /GED from an accredited school or institution with a minimum 7 years of experience along with established leadership across the discipline and function) Have minimum 5 years of experience along with established leadership across the discipline and function.  Desired Characteristics:  Aptitude, experience and/or passion for the creation and execution of an enterprise-grade storage & backup team & environment Extensive experience in storage Operations management, backup systems, SAN, NAS, DR Working knowledge of systems from major data storage vendors and cloud services Working knowledge of technical aspects of storage systems \u2013 including but not limited to DAS, NAS, Fiber Channel, RAID config, LUN Masking Process improvement and storage provisioning automation  Work in a way that works for you  We recognize that everyone is different and that the way in which people want to work and deliver at their best is different for everyone too. In this role, we can offer the following flexible working patterns:  Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive  Working with us  Our people are at the heart of what we do at Baker Hughes. We know we are better when all of our people are developed, engaged and able to bring their whole authentic selves to work. We invest in the health and well-being of our workforce, train and reward talent and develop leaders at all levels to bring out the best in each other.  Working for you  Our inventions have revolutionized energy for over a century. But to keep going forward tomorrow, we know we have to push the boundaries today. We prioritize rewarding those who embrace change with a package that reflects how much we value their input. Join us, and you can expect:  Contemporary work-life balance policies and wellbeing activities Comprehensive private medical care options Safety net of life insurance and disability programs Tailored financial programs Additional elected or voluntary benefits  About Us  With operations in over 120 countries, we provide better solutions for our customers and richer opportunities for our people. As a leading partner to the energy industry, we're committed to achieving net-zero carbon emissions by 2050 and we're always looking for the right people to help us get there. People who are as passionate as we are about making energy safer, cleaner and more efficient.  Join Us  Are you seeking an opportunity to make a real difference in a company with a global reach and exciting services and clients? Come join us and grow with a team of people who will energize and inspire you!  About Us:  With operations in over 120 countries, we provide better solutions for our customers and richer opportunities for our people. As a leading partner to the energy industry, we\u2019re committed to achieving net-zero carbon emissions by 2050 and we\u2019re always looking for the right people to help us get there. People who are as passionate as we are about making energy safer, cleaner and more efficient.  Join Us:  Are you seeking an opportunity to make a real difference in a company that values innovation and progress? Join us and become part of a team of people who will challenge and inspire you! Let\u2019s come together and take energy forward.  Baker Hughes Company is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.  R52391",
        {
            "entities": [
                [
                    1812,
                    1815,
                    "TOOL"
                ],
                [
                    1823,
                    1828,
                    "TOOL"
                ],
                [
                    1849,
                    1857,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Reference No: WD-0013592  What's the role?  In the role of Data Engineer, you will be part of the Global Enterprise Data Lake Team developing, deploying and maintaining big data platforms to support advanced analytics and business intelligence needs of Hilti business and function worldwide. This role will require you to work closely with key stakeholders from the business globally and cross IT team to integrate and transform required data into the Data Lake Platform.  Who is Hilti?  We provide leading-edge tools, technologies, software and services for the global construction sector. Hilti is a multicultural workplace with 55 different nationalities committed to global teamwork.  Global IT within Hilti is a truly global team with main hubs in Buchs (Switzerland), Kuala Lumpur (Malaysia) and Plano/Tulsa (USA). All locations have highly competent teams who work very closely together. Hilti`s Global IT team is known for their focus on sustainable value creation by translating latest IT innovations into value creating solutions & services.  What does the role involve?  In your role as Data Engineer, you will interact directly with various stakeholders (business users, data scientists, analytics teams) to understand their data demand and in turn, design and develop scalable ETL packages from the business source systems, including development of ETL routines, to bring these data into the enterprise data platforms.  The Role Will Require You To  be responsible to create databases optimized for performance, implementing schema changes and maintaining data architecture standards across the centrally provision business databases.  be responsible to perform thorough testing and validation in order to support the accuracy of data transformations.  lead innovation through exploration, benchmarking, making recommendations and implementing big data technologies.  Working together as a team, you will ensure the delivery of sustainable solutions that support the organization\u2019s long-term goals while delivery maximum incremental short-term gains.  The Global IM team is embarking on an exciting journey to transform the reporting landscape of the organization, moving from hindsight reporting to analytics, insights and foresight that will enable employees at all levels to make the best decision to drive business outcome. In the Enterprise Data Lake portfolio, we have implemented both Azure Managed Instance and AWS S3 technologies to drive our big data agenda and support Hilti\u2019s digital marketing and sales ambition.  What do we offer?  Show us what you\u2019re made of and we\u2019ll offer you opportunities to move around the business \u2013 to work abroad, experience different job functions and tackle different markets. It\u2019s a great way to find the right match for your ambitions and achieve the exciting career you\u2019re after.  We have a very thorough people review process, unlike any we know of in any other business. We can pair talent with opportunities - developing our people in their current roles or challenging them to work in new ways or in new places. It\u2019s how we find the right fit, further our teams personally and professionally, get the best value for each employee and increase the job satisfaction. Additionally, we offer you a wide range of benefits.  Why should you apply?  Become a valuable member of our highly professional and international team of IT experts and meet the challenges of a global multinational company using latest technologies. You will have the freedom to act in the responsible area with career prospects in a dynamic environment, excellent opportunities to develop yourself to higher levels and wider range of knowledge. Our team in Kuala Lumpur is a recognized and respected competence center that is covering all relevant areas of IT. Furthermore, 80% of our top positions are filled internally. We have a clearly defined career development track for every individual employee and an excellent team whom are duly rewarded by performance.  What You Need Is At least a Bachelor\u2019s Degree in Computer Science/Information Technology, Engineering (Computer/Telecommunication), Science & Technology or equivalent; a Master\u2019s Degree is an advantage for this position. At least 1 years of working experience as database engineering support personnel or database engineering administrator within a fast-paced complex business setting. Strong analytical skills, showing fluency in tools such as Microsoft SQL and MySQL, and strong Python, PowerShell programming skills. Ability to design, build, and maintain business\u2019s ETL pipelines and data warehouse. Expertise in data modelling and query performance tuning on SQL server, MySQL, Redshift or other similar platforms Experience with SAP and/or Salesforce data integration, and data visualization tools such as Microsoft Power BI is highly desirable Result-driven, innovative problem solver, self-motivated and proactive, highly organized, ability to handle multiple tasks meeting aggressive timelines Excellent verbal and written communication skills in English and can engage with stakeholders from different disciplines in all levels of the organization. A strong team player; able to work with a team that have members from various background. Experience working in a virtual global team is highly desirable. Interested for the role?  Click through the 'Apply Now' button where you will be asked to upload your CV and answer a couple of short questions \u2013 the whole process should take around 90 seconds. If we like what we see, you'll be invited to a telephone interview.  If we don't have a suitable role for you at the moment, we will keep you in our talent pool for the future so your recruitment process might take a bit longer but we'll be sure to stay in touch.  #JoinHiltiAsiaITServices  Looking forward to hearing from you!  \u201cI love the fact that my job isn\u2019t just technical. It involves planning and dealing with people too. The culture is brilliant. It\u2019s challenging, yes, but it\u2019s friendly and welcoming too. It\u2019s all about teamwork, and your ideas are really taken on board.\u201d Andreas, Head of Corporate Research and Technology",
        {
            "entities": [
                [
                    2405,
                    2410,
                    "TOOL"
                ],
                [
                    2432,
                    2435,
                    "TOOL"
                ],
                [
                    2436,
                    2438,
                    "PROGLANG"
                ],
                [
                    4022,
                    4030,
                    "EDUCATION"
                ],
                [
                    4164,
                    4170,
                    "EDUCATION"
                ],
                [
                    4449,
                    4452,
                    "PROGLANG"
                ],
                [
                    4457,
                    4462,
                    "TOOL"
                ],
                [
                    4475,
                    4481,
                    "PROGLANG"
                ],
                [
                    4483,
                    4493,
                    "PROGLANG"
                ],
                [
                    4658,
                    4661,
                    "PROGLANG"
                ],
                [
                    4670,
                    4675,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "Company Description  At Western Digital, our vision is to power global innovation and push the boundaries of technology to make what you thought was once impossible, possible.  At our core, Western Digital is a company of problem solvers. People achieve extraordinary things given the right technology. For decades, we\u2019ve been doing just that. Our technology helped people put a man on the moon.  We are a key partner to some of the largest and highest growth organizations in the world. From energizing the most competitive gaming platforms, to enabling systems to make cities safer and cars smarter and more connected, to powering the data centers behind many of the world\u2019s biggest companies and public cloud, Western Digital is fueling a brighter, smarter future.  Binge-watch any shows, use social media or shop online lately? You\u2019ll find Western Digital supporting the storage infrastructure behind many of these platforms. And, that flash memory card that captures and preserves your most precious moments? That\u2019s us, too.  We offer an expansive portfolio of technologies, storage devices and platforms for business and consumers alike. Our data-centric solutions are comprised of the Western Digital\u00ae, G-Technology\u2122, SanDisk\u00ae and WD\u00ae brands.  Today\u2019s exceptional challenges require your unique skills. It\u2019s You & Western Digital. Together, we\u2019re the next BIG thing in data.  Job Description Work with Equipment engineers and IT to integrate Equipment Data, MES, Cassette Labelling into a Product Traceability System for new 25 million factory.. Work with EDM to integrate 25 million factory KPOV into Media E2E and eventually establish Surface Level Linkage to HDD. Support expansion process qual team in Data Mining. Capitalize on 25 million factory which has higher level of Equipment Automation and drive for Data Automation. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with data and analytics experts to strive for greater functionality in our data systems. Qualifications  Bachelor Degree in Computer Engineering/Computer Science/Electronics Engineering or related Discipline. 2 years working experience is preferred.",
        {
            "entities": [
                [
                    2125,
                    2133,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Featured  Data Engineer  Job Description  Job Responsibilities: Work closely with the data analysts to translate requirement into data feeds Ensures Non Functional Requirements can be met within the proposed solution. Documents the ETL components ready for implementation. Designs and documents pipelines in the context of the overall architecture. Develops ETL pipelines and transformation logic. Peer review Pipeline code and ensure standards are met. Develops complex SQL scripts, stored procedures. Understands SSIS ETL pipelines and can update and maintain the processes. Expert skills in development of python scripts and use of standard libraries. Expands the ETL frameworks in line with the architecture requirements. Job Requirements Bachelor's or master's degree in data science, information technology or equivalent 3+ years of working experience in Data Engineering and/or Software Engineering, 2+ years of recent Python development experience or equivalent programming language (Java, C#, Scala) Advanced knowledge of Standard Query Language (SQL) Advantageous to have Bigdata development experience e.g. Spark, Storm or similar Experience working with Data Lakes ideally Azure Data Lake. MSSQL and SSIS experience a plus AZURE Synapse experience a plus How to Apply?  To apply, please click \"APPLY NOW\" or email Sandara Phan at  Due to the volume of applications received, we regret to inform you that only shortlisted candidates will be notified.  JTK Number: JTKSM 995 | Company Registration Number: 201301019088 (1048918-T)  If this job isn't quite right for you, but you know someone who would be great at this role, why not take advantage of our referral scheme? We offer MYR500 in shopping vouchers for every referred candidate who we place in a role. Terms & Conditions Apply.",
        {
            "entities": [
                [
                    471,
                    474,
                    "PROGLANG"
                ],
                [
                    609,
                    615,
                    "PROGLANG"
                ],
                [
                    743,
                    751,
                    "EDUCATION"
                ],
                [
                    757,
                    763,
                    "EDUCATION"
                ],
                [
                    926,
                    932,
                    "PROGLANG"
                ],
                [
                    992,
                    996,
                    "PROGLANG"
                ],
                [
                    998,
                    1000,
                    "PROGLANG"
                ],
                [
                    1002,
                    1007,
                    "PROGLANG"
                ],
                [
                    1056,
                    1059,
                    "PROGLANG"
                ],
                [
                    1118,
                    1123,
                    "TOOL"
                ],
                [
                    1185,
                    1190,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "Provide innovative solutions using latest data analytics technologies to drive decision making and revenue generation. Work closely with analysts and stakeholders to understand their business requirements and build effective solutions. Create visualization solutions using web technologies and 3rd party frameworks. To design and build scalable, reusable components and frameworks and adhere to best practice. To contribute ideas and input and play an integral role in the team. Minimum 3-6 years onwards of relevant working experience. Must be familiar with Python (Pandas, Numpy, Jupyter etc) Familiar with visualization frameworks such as Power BI, Plotly, Plotly Dash. Experience in data analysis and strong hands-on knowledge of time series data manipulation. Proficient in writing highly reliable, tuned (pythonic) numerical code. Good understanding of web services and the ability to integrate with REST APIs. Relevant experience of large-scale data analysis and predictive modelling is an added advantage.",
        {
            "entities": [
                [
                    559,
                    565,
                    "PROGLANG"
                ],
                [
                    567,
                    573,
                    "LIBRARY"
                ],
                [
                    575,
                    580,
                    "LIBRARY"
                ],
                [
                    582,
                    589,
                    "TOOL"
                ],
                [
                    652,
                    658,
                    "LIBRARY"
                ],
                [
                    660,
                    666,
                    "LIBRARY"
                ]
            ]
        }
    ],
    [
        "Imagine a future where you develop cloud-based platform solutions that enable the use of data across disciplines and business areas  Join us in this role where you\u2019ll get the opportunity to design and build end-to-end data engineering solutions that provide the foundation for an enterprise platform for cloud-based analytics across the company. You\u2019ll be delivering in the Dongeons & Dragons (D&D) Agile Release Train (ART) and will work closely with product owners, subject matter experts, and business stakeholders. You\u2019ll also advise the business on how to enable data to increase business value.  Welcome to Platforms & Integration Competency Centre  You\u2019ll be part of the Platforms & Integration Competency Centre where you, together with your colleagues, will work on developing the Group\u2019s data backbone, inspiring and advising stakeholders on how to enable data. The team consists of professionals who are passionate about data management, data engineering, data science, and integration technologies. We\u2019re committed to delivering on our organisation\u2019s digital strategy and creating a strong platform for analytics, model management, machine learning, etc., all of which all are built on cloud technologies.  You\u2019ll play an important role in: writing production-grade, peer-reviewed SQL, and Python code, with automated tests building, evolving, and maintaining the ingestion pipelines to the \u00d8rsted Data Ecosystem and ensuring that data is made available in a way that is optimised for security, stability, and performance maintaining a constant dialogue with the business data scientist community to find ways to optimise data packaging and structuring to enable reuse and support of common business scenarios participating in developing the capabilities and governance of the data platform setting up the monitoring and orchestration of data pipelines. To succeed in the role, you: have significant development experience using Python and substantial experience with RDBMS and SQL experience working with PySpark experience building REST APIs in Python or C# have solid experience with cloud platforms and container technology, preferably Docker have experience monitoring and orchestrating data pipelines in Azure DevOps. Join a world leader in green energy  \u00d8rsted is a global leader in offshore wind energy and ranked the world\u2019s most sustainable energy company. To be a frontrunner, we invest significantly in employee development, and from the moment you join us, we\u2019ll support your personal and professional growth. Here, you\u2019ll get the opportunities that will unleash your full potential, and you\u2019ll experience a collaborative, diverse, and dynamic work environment.  Shape the future with us  Send your application to us no later than 31 May 2022. We\u2019ll be conducting interviews on a continuous basis. If you need to request any adjustments to working practices, working patterns, or the assessment process we're happy to discuss alternative arrangements.  Please don\u2019t hesitate to contact Talent Acquisition Operations MY, , on talentacquisitionMY@orsted.com if you\u2019d like to know more about the position.  Please note that for your application to be taken into consideration, you must submit your application via our online career pages and answer the screening questions relevant for your country.",
        {
            "entities": [
                [
                    1293,
                    1296,
                    "PROGLANG"
                ],
                [
                    1302,
                    1308,
                    "PROGLANG"
                ],
                [
                    1941,
                    1947,
                    "PROGLANG"
                ],
                [
                    1990,
                    1993,
                    "PROGLANG"
                ],
                [
                    2059,
                    2065,
                    "PROGLANG"
                ],
                [
                    2069,
                    2071,
                    "PROGLANG"
                ],
                [
                    2222,
                    2227,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "Our vision is to transform how the world uses information to enrich life for all.  Join an inclusive team passionate about one thing: using their expertise in the relentless pursuit of innovation for customers and partners. The solutions we build help make everything from virtual reality experiences to breakthroughs in neural networks possible. We do it all while committing to integrity, sustainability, and giving back to our communities. Because doing so can fuel the very innovation we are pursuing.  JR17917 Systems and Data Engineer  Responsibilities Include, But Not Limited To  Work closely with key stakeholders on systems setup and deployment that are critical for plant startup. Respond quickly to systems related issues, analyze, and resolve system failure mechanism through effective problem solving. Admin and SME for Recipe Management System (RMS) and Autoshell User Interface(AUI) systems. Support Engineering and site\u2019s requirement in generating automated operational dashboards. Support Engineering and site\u2019s requirement in tasks automation for productivity improvement, example via Robotic Processing Automation (RPA). Support Engineering and site\u2019s requirement in data extraction, processing, and translating data into knowledge and insights. Manages site\u2019s Resource Demand Management (RDM) requests, working closely with Engineering Director and IT team to prioritize improvement requests. Admin for Engineering department sharepoint.  Education/Requirement  Degree in Engineering / IT or equivalent. Strong desire to grow career as systems and data engineering in highly automated industrial manufacturing doing analysis on diverse datasets. Basic coding skills on languages such as but not limited to SQL, VB, Excel, C, etc. Good verbal and written communication skills. Ability to work independently, and values collaboration with other team members. Ability to extract data from different databases via SQL and other query languages, and apply data cleansing, outlier identification, and missing data techniques. Ability to pick up skillsets necessary to build engineering and operational reports utilizing platform such as Tableau, PowerBI.  About Micron Technology, Inc.  We are an industry leader in innovative memory and storage solutions transforming how the world uses information to enrich life for all. With a relentless focus on our customers, technology leadership, and manufacturing and operational excellence, Micron delivers a rich portfolio of high-performance DRAM, NAND, and NOR memory and storage products through our Micron\u00ae and Crucial\u00ae brands. Every day, the innovations that our people create fuel the data economy, enabling advances in artificial intelligence and 5G applications that unleash opportunities \u2014 from the data center to the intelligent edge and across the client and mobile user experience.  Please note that in order to assist in providing a safe and healthy workplace for all Micron team members, new employment offers for jobs based in India, Malaysia, Singapore, and the U.S., are contingent upon the applicant\u2019s provision of a copy of their COVID-19 vaccination document to Micron on a confidential basis prior to their scheduled start date confirming that they have completed the COVID-19 vaccination process, subject to any written request for medical or religious accommodation and to the extent permitted by applicable law.  To learn more, please visit micron.com/careers  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.  To request assistance with the application process and/or for reasonable accommodations, please contact hrsupport_my@micron.com  Micron Prohibits the use of child labor and complies with all applicable laws, rules, regulations, and other international and industry labor standards.  Micron does not charge candidates any recruitment fees or unlawfully collect any other payment from candidates as consideration for their employment with Micron.",
        {
            "entities": [
                [
                    1727,
                    1730,
                    "PROGLANG"
                ],
                [
                    1736,
                    1741,
                    "TOOL"
                ],
                [
                    1743,
                    1744,
                    "PROGLANG"
                ],
                [
                    1931,
                    1934,
                    "PROGLANG"
                ],
                [
                    2152,
                    2159,
                    "TOOL"
                ],
                [
                    2161,
                    2168,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "About You  About the job Data Engineer  The position will require you to source data from internal systems and third-party systems to be stored in the data warehouse, code reviews, SQL code optimization. Dev ops experience is highly beneficial. Additionally, you would be required to support the data science team, BI team and insights in troubleshooting issues.  Your Day-to-Day SQL code review and optimization of existing deployed ETL scripts on Redshift. Review python scripts deployed for ETL pipelines. Maintenance and management of Redshift cluster. Monitoring ETL jobs running on Airflow. Deploy automations and alerts for monitoring the infrastructure and for reporting Data Anomalies on business metrics. Cost efficiency management for infrastructure.  Your Know-How Bachelors in Computer Science, Software Engineering or any related fields. 2-4 years of experience as a Data Engineer. Cloud Certifications - Solution Architect (Nice to have). ETL and API development experience using Python. SQL & data modelling experience. Experience in using Redshift, Athena. Experience using AWS or other cloud platforms. Experience using docker for creating deployments.  Please click the link to apply / submit your Updated CV here: CLICK HERE",
        {
            "entities": [
                [
                    181,
                    184,
                    "PROGLANG"
                ],
                [
                    380,
                    383,
                    "PROGLANG"
                ],
                [
                    466,
                    472,
                    "PROGLANG"
                ],
                [
                    995,
                    1001,
                    "PROGLANG"
                ],
                [
                    1003,
                    1006,
                    "PROGLANG"
                ],
                [
                    1091,
                    1094,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "If you are hungry to make a difference with one of the most well known low-cost airlines and to work in the dynamic technology hub, this is the job for you.  AirAsia.com\u2019s data team drives conversion, personalisation, and revenue growth across flights and other lines of business. We are looking for Allstars to join an innovative and dynamic team which works in tandem with product and tech. You will help develop the future models and tools to drive better decisions and growth.  Duties and Responsibilities: Strong ETL/ELT workflow experience in design, configuration, data mapping, extraction, transformation and loading in a complex environment processing large volumes of data Hands on experience in building any of ML services like MLflow / AI Platform / Tensorflow / SageMaker is a MUST Proven experience in handling Unstructured data Proven experience in migration project is a MUST Proven experience leading ML project is a MUST Hands on experience in deploying Kubernetes / Openshift / GKE / EKS is a MUST Strong hands on expertise with Linux is a MUST Strong hands on expertise with any of programming language is a MUST Strong hands on expertise with Spark is a MUST Strong hands on expertise with PLSQL is a MUST Strong experience in building custom Data Transformation using open source ETL/ELT tools such as Airflow, Nifi, Airbyte, Oozie, DBT Data Lake high level principles and understanding of Big Data ecosystems Data warehousing principles and business intelligence understanding Experience with any cloud practice is a PLUS  About You: BS/MS/PhD in IT, Mathematics, Science or Engineering discipline 9 - 10 years of relevant experience in Data Engineering/Data Science 1+ years experience in Machine Learning Engineering Familiar with containerization and orchestration tools Familiar with Google Cloud Platform and its tools and services Ability to work under pressure and change, and balance among speed, reliability, interpretability Good working knowledge of productivity tools such as G Suite, Git, Jira, Confluence. Experience with code versioning, code review and documentation Proficient understanding of distributed computing principles  We are all different - one talent to another - that is how we rely on our differences. At AirAsia, you will be treated fairly and given all chances to be the best. We committed to creating a diverse work environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.  Search Firm Representatives - AirAsia does not accept unsolicited assistance from search firms for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position-specific. We are all different - one talent to another - that is how we rely on our differences. At AirAsia, you will be treated fairly and given all chances to be the best. We committed to creating a diverse work environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.  Search Firm Representatives - AirAsia does not accept unsolicited assistance from search firms for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position-specific.",
        {
            "entities": [
                [
                    739,
                    745,
                    "TOOL"
                ],
                [
                    972,
                    982,
                    "TOOL"
                ],
                [
                    1164,
                    1169,
                    "TOOL"
                ],
                [
                    2020,
                    2023,
                    "TOOL"
                ],
                [
                    2025,
                    2029,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "Analyze the Business rule with users, transform the Business rules into Mapping and functional specification document . Development of data ingestion, integration and extraction pipelines with data lake. Write robust, reliable and maintainable code Write clear and concise documentation, including business logic implemented per required transformations Resolve issues with a high degree of analytical aptitude and foresight Enforce and adhere to defined processes and procedures, best practices and standards Proficiency in database structures, theories, principles and practices in particular with data warehouse design ETL experience in design, mapping and configuration in a complex environment processing large volumes of data Strong SQL experience and/or SQL Server databases. Good knowledge of Big Data querying tools, such as Hive & Hue and etc. Possess proven knowledge of one or more Azure technologies - Microsoft SQL Server Information Services, Microsoft Data Quality Service, Azure Cloud and Power BI Expose data to end users for using modern visualization platform (i.e. PowerBI, Azure API Apps) Implement effective metrics and monitoring processes Required Skills Proficient with at least one or more of the following technologies: SSIS, SQL Skills, SQL Server, Azure Data Factory, Data Warehouse, ETL Framework, Microsoft PowerBI Advanced knowledge of SQL Preferably possess a good knowledge about: Data Modelling, Data APIs, Unstructured Data and Hadoop Ecosystem Information Security, Encryption, SSL/TLS SAAS experience Azure/AWS Technical authoring for product/project documentation System Integration Architecture, Enterprise Integration Patterns File based integrations Knowledge with Apache Kafka is add-on advantage Qualification  Bachelor's Degree in IT software development/engineering or Data Science related discipline  Years Of Experience  Intermediate (2 \u2013 4 years experience)",
        {
            "entities": [
                [
                    739,
                    742,
                    "PROGLANG"
                ],
                [
                    761,
                    764,
                    "PROGLANG"
                ],
                [
                    894,
                    899,
                    "TOOL"
                ],
                [
                    925,
                    928,
                    "PROGLANG"
                ],
                [
                    990,
                    995,
                    "TOOL"
                ],
                [
                    1086,
                    1093,
                    "TOOL"
                ],
                [
                    1095,
                    1100,
                    "TOOL"
                ],
                [
                    1254,
                    1257,
                    "PROGLANG"
                ],
                [
                    1266,
                    1269,
                    "PROGLANG"
                ],
                [
                    1278,
                    1283,
                    "TOOL"
                ],
                [
                    1339,
                    1346,
                    "TOOL"
                ],
                [
                    1369,
                    1372,
                    "PROGLANG"
                ],
                [
                    1465,
                    1471,
                    "TOOL"
                ],
                [
                    1540,
                    1545,
                    "TOOL"
                ],
                [
                    1546,
                    1549,
                    "TOOL"
                ],
                [
                    1708,
                    1720,
                    "TOOL"
                ],
                [
                    1756,
                    1764,
                    "EDUCATION"
                ]
            ]
        }
    ],
    [
        "Company Description  The future. It\u2019s on you. You & Western Digital.  We\u2019ve been storing the world\u2019s data for more than 50 years. Once, it was the most important thing we could do for data. Now we\u2019re helping the world capture, preserve, access and transform data in a way only we can.  The most game-changing companies, consumers, professionals, and governments come to us for the technologies and solutions they need to capture, preserve, access, and transform their data.  But we can\u2019t do it alone. Today\u2019s exceptional data challenges require your exceptional skills. It\u2019s You & Us. Together, we\u2019re the next big thing in data.  Western Digital\u00ae data-centric solutions are found under the G-Technology\u2122, HGST, SanDisk\u00ae, Tegile\u2122, Upthere\u2122, and WD\u00ae brands.  Job Description Responsible to develop software programs, algorithms and automated processes to clean and evaluate huge amount of datasets from multiple sources. Responsible for systems maintaining consistent data quality. Collaborate with Data Analytics team to integrate and implement large scale data solution. Collaborate with Production team for Equipment FMEA, OCAP and Control Plan in related process. Participate in fast-paced prototyping to identify improvement opportunities in manufacturing systems. Qualifications Bachelor/Master in Software Engineering/Computer Science. Proficiency in programming language (Python, SQL) or other data analysis tools (Matlab, JMP, Minitab) Added Advantage: Data Science major. Knowledge of semiconductor manufacturing process or equipment. Knowledge in sensors, drivers and encoder will be an added advantage. Familiarity with Data Processing Tools (Kafka, Spark, Apache Nifi, Dataiku). Familiarity with No-SQL databases (Cassandra, Mongo, HDFS). Familiarity with software engineering tools (JIRA, Jenkins, Git, Confluence). Excellent knowledge of algorithms and data structures. Additional Information  Because Western Digital thrives on the power of diversity and is committed to an inclusive environment where every individual can thrive through a sense of belonging, respect, and contribution, we are committed to giving every qualified applicant and employee an equal opportunity. Western Digital does not discriminate against any applicant or employee based on their protected class status and complies with all federal and state laws against discrimination, harassment, and retaliation, as well as the laws and regulations set forth in the \"Equal Employment Opportunity is the Law\" poster.",
        {
            "entities": [
                [
                    1283,
                    1291,
                    "EDUCATION"
                ],
                [
                    1292,
                    1298,
                    "EDUCATION"
                ],
                [
                    1378,
                    1384,
                    "PROGLANG"
                ],
                [
                    1386,
                    1389,
                    "PROGLANG"
                ],
                [
                    1660,
                    1665,
                    "TOOL"
                ],
                [
                    1710,
                    1713,
                    "PROGLANG"
                ],
                [
                    1725,
                    1734,
                    "TOOL"
                ],
                [
                    1801,
                    1808,
                    "TOOL"
                ],
                [
                    1810,
                    1813,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "AirAsia.com\u2019s data team drives conversion, personalisation, and revenue growth across flights and other lines of business. We are looking for Allstars to join an innovative and dynamic team which works in tandem with product and tech. You will help develop the future models and tools to drive better decisions and growth. Duties and Responsibilities: Strong ETL/ELT workflow experience in design, configuration, data mapping, extraction, transformation and loading in a complex environment processing large volumes of data Hands on experience in building any of ML services like MLflow / AI Platform / Tensorflow / SageMaker is a MUST Proven experience in handling Unstructured data Proven experience in migration project is a MUST Proven experience leading ML project is a MUST Hands on experience in deploying Kubernetes / Openshift / GKE / EKS is a MUST Strong hands on expertise with Linux is a MUST Strong hands on expertise with any of programming language is a MUST Strong hands on expertise with Spark is a MUST Strong hands on expertise with PLSQL is a MUST Hands on experience with Docker is a MUST Strong experience in building custom Data Transformation using open source ETL/ELT tools such as Airflow, Nifi, Airbyte, Oozie Data Lake high level principles and understanding of Big Data ecosystems Data warehousing principles and business intelligence understanding Experience with any cloud practice is a PLUS Experience with streaming project is a PLUS About You: BS/MS/PhD in IT, Mathematics, Science or Engineering discipline 5 - 7 years of relevant experience in Data Engineering 1+ years experience in Machine Learning Engineering Experience with pipeline and workflow management tools. Must have some experience in deploying real time pipelines Familiar with containerisation and orchestration tools Familiar with Google Cloud Platform and its tools and services Ability to work under pressure and change, and balance among speed, reliability, interpretability Good working knowledge of productivity tools such as G Suite, Git, Jira, Confluence. Experience with code versioning, code review and documentation Proficient understanding of distributed computing principles We are all different - one talent to another - that is how we rely on our differences. At AirAsia, you will be treated fairly and given all chances to be the best. We committed to creating a diverse work environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. Search Firm Representatives - AirAsia does not accept unsolicited assistance from search firms for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position-specific.",
        {
            "entities": [
                [
                    580,
                    586,
                    "TOOL"
                ],
                [
                    813,
                    823,
                    "TOOL"
                ],
                [
                    1005,
                    1010,
                    "TOOL"
                ],
                [
                    2042,
                    2045,
                    "TOOL"
                ],
                [
                    2047,
                    2051,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "We Are Looking For Data Engineers Who Are highly motivated and are excited by the prospect of optimizing or even re-designing our company\u2019s data architecture to support our next generation of product and data. Are passionate about truly changing the world and making a big impact by contributing to the development of a significant product that will impact the future of HR globally Truly enjoy working in a team and collaborating with others to understand, discover and recommend ways to optimize our product and improve user experience using data Are always looking to learn and improve \u2013 independent self-learners who love to share what they find Have a self-driven work ethic \u2013 self-starters who love taking initiative and seeing things through to completion What You Will Do Design, develop, monitor and operate data integration pipelines processing millions of records to provide high quality datasets for analytical and machine learning use-cases. Build measures of data quality and automated tests of the quality of data powered features. Leverage and improve cloud-based (e.g. AWS and GCP) tech stack. Consult stakeholders including C-Suite and tech team to build and continuously improve \u201cSingle Source of Truth\u201d data products that create value for clients. Be a sparring partner to other team members and provide support and guidance to other engineers to help develop their technical capabilities. You Meet All Or Most Of These Requirements Bachelor degree required with at least 2 \u2013 3 years experience in a Data Engineer role, preferably with a degree in computer science, electrical engineering, mathematics or any other quantitative field. Solid programming skills in Python. Experience in performing data analysis with optimized SQL. Proficient knowledge in developing data pipelines with Apache Beam for cloud-based analytics is a plus. Knowledge of workflow management tools such as Apache Airflow. Hands-on experience in cloud technologies (AWS, GCP preferred) and container technology tools (Docker). Experience in all the steps of the engineering process, including testing, continuous integration/continuous delivery, automated deployment and monitoring. Strong analytical and problem-solving skills, with the ability to comprehend and troubleshoot from a data & design point of view, and propose sustainable solutions Able to own mistakes, reflect and take feedback with maturity and a willingness to improve.",
        {
            "entities": [
                [
                    1086,
                    1089,
                    "TOOL"
                ],
                [
                    1142,
                    1143,
                    "PROGLANG"
                ],
                [
                    1453,
                    1461,
                    "EDUCATION"
                ],
                [
                    1683,
                    1689,
                    "PROGLANG"
                ],
                [
                    1745,
                    1748,
                    "PROGLANG"
                ],
                [
                    1960,
                    1963,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "Job Profile Summary Responsible for supporting the delivery of business analysis and consulting processes and procedures for the defined specialism using sound technical capabilities, building and maintaining effective working relationships, ensuring relevant standards are defined and maintained, and supporting delivery of process and system improvements. Specialisms: Business Analysis; Data Management and Data Science; Digital Innovation.  Job Advert The Identity & Access Management (IAM) team are building a key data & analytics capability and service offering to provide analytical capabilities both internally and externally to consumers and customers of identity and access data. We are looking for a highly competent Data Analysts to help establish these services and to provide actionable, data-driven business insights by combining statistical skills, data manipulation capabilities and business acumen to achieve the desired outcomes.  Key Accountabilities The role will be part of the Identity & Access Management (IAM) portfolio within Enterprise & Operations (DE&O) and part of the IAM Data & Analytics team with accountability to: Work directly with the IAM Data & Analytics Staff Platform Engineer / Product Manager as part of the IAM Data & Analytics devops squad Proactively work with the team in IAM to define, gathering and articulate the business requirements to enable the translation into tangible analytical reports and visualisations to create data and analytics solutions in support of IAM analytics goals Work directly with the data through Azure Data Explorer, PowerBI or DataIKU to perform adhoc queries, data analysis and data discovery helping draw out insights from IAM data sets Be an active member of the devops team supporting agile practices and processes in the way work is delivered Helping prioritise backlogs across all IAM Data & Analytics products and features Facilitate the interface between the IAM customers and the Security Data Services (SDS) working closely with the Security Data Services (SDS) data lake team on delivery of use cases Work with the Security Data Services (SDS) to define and implement data schemas for the Identity & Access Management data domain Assist the team in data related queries/issues and address them in a timely fashion Contribute to the continuous improvement by supporting others in the team and improving the quality standards and efficiency of delivery Build awareness of internal and external technology developments Advocate and help ensure our architectures, designs and processes enhance a culture of operational safety and improve our digital security Key Requirements Preferably a Bachelor's (or higher) degree, preferably in Computer Science, MIS/IT, Mathematics or a hard science 10 years, with a minimum of at least 3 years\u2019 experience in Analytics / Data management. No prior experience in the energy industry required Ability to take initiative and work semi-autonomously to drive requirements and work delivery Experience with data analytics BI tools preferably Microsoft Power BI Ability to quickly develop appreciation for value that may be within data and able to guide teams on how to best draw out insights and value Good understanding of commonly available statistics approaches Able to write and maintain moderately complex data pipelines including scripting in R or python and good SQL skills Clear understanding of the end-to-end lifecycle of data Good understand of the application of data privacy and treatment of sensitive and personal data especially customer and consumer data Experience working as an agile team member and familiar with agile practices and processes A high Level of proficiency in Microsoft packages (Excel, PowerPoint etc) Good time management and organisation skills along with good communication skills Preferred Criteria / Skills: Experience working with identity & access management related data sets and IAM processes with awareness of related identity domains including consumer identity, identity protection and application access governance #bpDigitalEngineering  Entity Innovation & Engineering  Job Family Group IT&S Group  Relocation available No  Travel Required No  Country Malaysia  About BP INNOVATION & ENGINEERING Join us in creating, growing, and delivering innovation at pace, enabling us to thrive while transitioning to a net zero world. All without compromising our operational risk management.  Working With Us, You Can Do This By deploying our integrated capability and standards in service of our net zero and safety ambitions driving our digital transformation and pioneering new business models collaborating to deliver competitive customer-focused energy solutions originating, scaling and commercialising innovative ideas, and creating ground-breaking new businesses from them protecting us by assuring management of our greatest physical and digital risks Because Together We Are Originators, builders, guardians and disruptors Engineers, technologists, scientists and entrepreneurs Empathetic, curious, creative and inclusive Experience Level Intermediate  Legal disclaimer We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, sex, gender, gender expression, sexual orientation, age, marital status, neurodiversity/neurocognitive functioning, veteran status or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform crucial job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodations.",
        {
            "entities": [
                [
                    1571,
                    1576,
                    "TOOL"
                ],
                [
                    1592,
                    1599,
                    "TOOL"
                ],
                [
                    2672,
                    2680,
                    "EDUCATION"
                ],
                [
                    3366,
                    3367,
                    "PROGLANG"
                ],
                [
                    3371,
                    3377,
                    "PROGLANG"
                ],
                [
                    3387,
                    3390,
                    "PROGLANG"
                ],
                [
                    3730,
                    3735,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "You\u2019ll Play An Important Role In  \uf0b7 writing production-grade, peer-reviewed SQL, and Python code, with automated tests  \uf0b7 building, evolving, and maintaining the ingestion pipelines to the Data Lake platform  and ensuring that data is made available in a way that is optimised for security,  stability, and performance  \uf0b7 maintaining a constant dialogue with the business data scientist community to find  ways to optimise data packaging and structuring to enable reuse and support of  common business scenarios  \uf0b7 participating in developing the capabilities and governance of the data platform  \uf0b7 setting up the monitoring and orchestration of data pipelines.  To Succeed In The Role, You  \uf0b7 have significant development experience using Python and substantial experience with  RDBMS and SQL  \uf0b7 have solid experience working with Spark/PySpark and NiFi  \uf0b7 have solid experience with cloud platforms and container technology, incl. Docker,  which we use  \uf0b7 have experience monitoring and orchestrating data pipelines  \uf0b7 have substantial experience with Linux and Linux-based applications  Job originally posted on GrabJobs. If you need to report this job please contact GrabJobs",
        {
            "entities": [
                [
                    76,
                    79,
                    "PROGLANG"
                ],
                [
                    85,
                    91,
                    "PROGLANG"
                ],
                [
                    740,
                    746,
                    "PROGLANG"
                ],
                [
                    790,
                    793,
                    "PROGLANG"
                ],
                [
                    832,
                    837,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "The Full-Stack Data Engineer role requires equal amounts of Business Operation Acumen, Software Engineering, and Data Management.  Job Responsibilities Create and maintain optimal data pipeline architecture Assemble large, complex data sets that meet functional / non-functional business requirements Ensure data integrity and quality Identify, design, and implement internal process improvements; automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and other technologies Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics Create data tools for analytics and data scientist team members to assist them in building and optimizing our business Leverage data visualization tools and techniques to maximize impact and value of data Provide support and work with cross-functional and multidisciplinary teams including the Management, Data, Product and Tech teams to assist with data-related technical issues and support their data infrastructure needs Manage external technical communication with various teams, and contribute to improving data governance policies. Keep up with current technology and industry developments. Job Requirements BS/MS/Ph.D. in a Business, IT, Mathematics, Science or Engineering discipline Minimum 5 years of relevant experience beyond the first degree Knowledge of programming languages like SQL, R, and Python Technical proficiency regarding database design development, data models, techniques for data mining and segmentation Experience in handling reporting packages like Business objects, programming (Javascript, XML, or ETL frameworks) databases Experience with code versioning, code review, and documentation Experience with pipeline and workflow management tools Familiar with containerization and orchestration tools Good working knowledge of productivity tools such as Big Query, DataStudio, Kubernetes and Tensorflow Knowledge of how to create and apply the most accurate algorithms to datasets in order to find solutions Proficient understanding of distributed computing principles Able to select and integrate big data tools and frameworks Problem-solving skills and openness to experimenting with new techniques and new ways of working Team-working and able to operate under pressure and change, and balance among speed, reliability, interoperability To be proficient in Web Development using Go/NodeJs more than 4 years of experience Great in Data Structure & algorithms, Aptitude, and problem solving Have a deep respect for the challenges associated with operating a large-scale system in production, and designs and implementations reflect that understanding. Have a solid understanding of OOP REST architecture with experience in RESTful implementation Applicants with experience using Google Cloud Platform are highly favored.",
        {
            "entities": [
                [
                    647,
                    650,
                    "PROGLANG"
                ],
                [
                    1647,
                    1650,
                    "PROGLANG"
                ],
                [
                    1652,
                    1653,
                    "PROGLANG"
                ],
                [
                    1659,
                    1665,
                    "PROGLANG"
                ],
                [
                    2158,
                    2168,
                    "TOOL"
                ],
                [
                    2663,
                    2665,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "At Prudential, we understand that success comes from the talent and commitment of our people. Together, we have a shared vision in securing the future of our customers and our communities. We strive to build a business that you can shape, an inclusive workplace where everyone\u2019s ideas are valued and a culture where we can thrive together. Our people stay connected and tuned in to what\u2019s happening around us, keeping us ahead of the curve. While focused on the long-term, we look to the future to bring growth, development and benefit to everyone whose lives we touch.  Data Engineer is responsible to Extract, Load and Transform (ELT) as well as manage the Change Data Capture (CDC) using Qlik Replicate to ingest data into Data Lake, Data Models, Data Marts and 7-Sisters Master Data Management platform that help establish data-driven decision-making across the organization.  This is a new Data Team (Tribe) under IT Department that will drive the Data Strategy for the organization. They will work with respective Data Owners to develop the data models, data marts and data analytics for the whole PruBSN organization, following the regional Data COE approach to maintain good data governance and develop the 7-Sisters Master Data Management. The Data Strategy for PruBSN will be executed via the \u2018Hub & Spoke\u2019 approach, the \u2018Hub\u2019 being this core Data Team under IT, collaborating and working with the respective department Data Stewards and PruBSN Data Heroes (Power BI superusers), i.e. the \u2018Spokes\u2019.  Key Accountabilities Serve as the technology evangelist to develop integrated solutions that demonstrate business value Work with business stakeholders to understand business priorities and optimize IT strategies to support them. Scope to include full lifecycle, from approach strategy, architecture design, solution development, through installation and deployment Design, develop and implement effective extract, transform and loading (ETL/ELT) based on data needs along with database solutions and models to be able to store and serve the data accordingly Perform assessments/gap analysis of current technology landscape and identify high impact areas of improvement Collaborate with relevant teams to deliver transformation roadmaps, optimization and standardization strategies Review data mapping, design and technical documentation Lead and enable data team members to gain new skillset and apply the skillset for deliverables Able to understand, translate business requirements and work on various source systems (IL, DCMS, RCS, BPM, UME, SunGL etc.) and databases (PostgreSQL, DB2, Oracle, Azure Synapse Analytics, MongoDB, etc.)  Performance Measures  Deliver a Unified Data Platform  Implementing Customer and Contract Master, Product and Pricing Master  Enable Customer Insight Platform  Publish and Subscribe Data for Artificial Intelligence / Business Intelligence use cases  Lead and guide team members to deliver data related projects on time and on budget  Ingest, Curate, and orchestrate data for data consumer  Review data mapping, design and technical documentation  Qualification and Experience  Data Engineer should be familiar with data science, business intelligence, and data analytics. He/she should have prior knowledge of data integration, data warehousing, modeling, business intelligence, and presentation concepts.  Required Skills For Data Engineer Must-Have Experience With Azure Data Tools:  A Data Engineer must possess experience working with Azure Data tools e.g. Azure Data Factory, Azure Data Lake, Azure Synapse and BI systems like Power BI, Tableau, SAP, and so on. Considering the power bi role, they must have experience in creating data-rich dashboards, writing DAX expressions, and implementing row-level security in Power BI. Also, they must be able to develop custom BI products that require knowledge of scripting languages and programming languages like R and Python.  One of the key attributes of a Data Engineer is to Extract, Load and Transform (ELT) as well as manage the Change Data Capture (CDC) using Qlik Replicate to ingest data into Data Lake, Data Models, Data Marts and 7-Sisters Master Data Management platform that help establish data-driven decision-making across the organization. Required Experience In Data-Specific Roles:  To become a Data Engineer, you should require a minimum experience of 2 or 3 years working with ETL tools, or any data-specific roles. They are expected to have sound knowledge of database management, SQL querying, data modeling, data warehousing and OLAP (Online Analytical Processing). Knowledge In Microsoft BI Stack:  There are many products and services from Microsoft that are widely used by large-scale enterprises for data warehousing, data management, analytics, reporting, and business intelligence. Knowledge and experience with Microsoft Business Intelligence stacks such as Power BI, Power Apps, Power Pivot, SSRS, SSIS, and SSAS is an added advantage. Software Development Skills:  He/she doesn\u2019t have to be an expert in software development, but in order to meet diversified needs, they must know how to develop a custom data structure to support BI solution and Application Programming Interface (API). It is essential to have an understanding of technical aspects as well as software development architecture to transform requirements into technical presence.",
        {
            "entities": [
                [
                    691,
                    695,
                    "TOOL"
                ],
                [
                    775,
                    781,
                    "EDUCATION"
                ],
                [
                    1225,
                    1231,
                    "EDUCATION"
                ],
                [
                    2089,
                    2092,
                    "PROGLANG"
                ],
                [
                    2583,
                    2593,
                    "TOOL"
                ],
                [
                    2600,
                    2606,
                    "TOOL"
                ],
                [
                    2608,
                    2613,
                    "TOOL"
                ],
                [
                    2633,
                    2640,
                    "TOOL"
                ],
                [
                    2739,
                    2745,
                    "EDUCATION"
                ],
                [
                    2767,
                    2773,
                    "EDUCATION"
                ],
                [
                    3416,
                    3421,
                    "TOOL"
                ],
                [
                    3488,
                    3493,
                    "TOOL"
                ],
                [
                    3510,
                    3515,
                    "TOOL"
                ],
                [
                    3530,
                    3535,
                    "TOOL"
                ],
                [
                    3547,
                    3552,
                    "TOOL"
                ],
                [
                    3591,
                    3598,
                    "TOOL"
                ],
                [
                    3715,
                    3718,
                    "PROGLANG"
                ],
                [
                    3912,
                    3913,
                    "PROGLANG"
                ],
                [
                    3918,
                    3924,
                    "PROGLANG"
                ],
                [
                    4066,
                    4070,
                    "TOOL"
                ],
                [
                    4150,
                    4156,
                    "EDUCATION"
                ],
                [
                    4501,
                    4504,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "SUMMARY OF MAIN TASKS  As the data engineering team is expanding in this new setup Data Analytics Centre, the data engineer is to assist in the development of data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. To work on optimal data delivery architecture that is consistent throughout ongoing projects for the organization  You will be responsible for: Construct, test, and maintain architectures such as databases and large-scale processing systems of data  Build processes supporting data transformation, data structures, metadata, dependency, and workload management using SQL and Azure \u2018big data\u2019 technologies  Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics  Create and maintain optimal data pipeline architecture and analytics infrastructure that enables almost every other function within the data scopes  Identify, design, and implement internal process improvements such as automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.  Build data lake and data tools for analytics and data science team members that assist them in building and optimizing our solution into an innovative industry leader  Work with stakeholders to identify the business requirements and the expected outcome especially on improving efficiency, productivity, and monetization using various data science methodology  Work with vendors/consultants on various analytics projects and apply the best practice for internal usage  Collaborate with different units in the Data Analytics Centre and other departments to support data collection, integration, and retention requirements  As a TEAM, you shall at all times act with HONESTY, INTEGRITY, and PROFESSIONALISM in providing the HIGHEST STANDARD OF SERVICES to our internal and external customers Notwithstanding the above, Company may assign other duties/responsibilities to the person holding this position based on prevailing business needs or for development reasons.  To be successful in this position, you need: At least a bachelor\u2019s degree in any of the following disciplines but not limited to Mathematics, Computer Science, Statistics, Economics, Actuarial, and Data Science 2 - 5 years of working experience in relevant database architecting, preparation, design, and modeling Advanced working SQL knowledge and experience working with relational databases Data Warehouse modeling (star schema, data vault) Experience in Power BI, SSAS, and DAX language Knowledge in Azure Data Warehouse and Azure Data Factory will be an added advantage Knowledge of database architecture, data modeling, data warehousing, ETL methodologies, and computer engineering Experience with SQL / Python / SAS / Tableau / R / SPSS / Adobe or other Machine Learning programming languages Experience with Hadoop/ Hybrid/ Cloud and other data storage tools Involved in the development of data marts, data lakes, and databases Proficient in Machine Learning and Artificial Intelligence  KNOWLEDGE Knowledge of various technological decision making for the business's future data, analysis, and reporting needs Have involved in the development of stakeholder-ready deliverables and presenting them with confidence and influence  SKILLS (PROFESSIONAL, TECHNICAL MANAGERIAL & PRACTICAL) Preferably to have attended Big Data Analytics short-term courses or have obtained certification in Data Science  ABILITIES Able to complete multiple tasks within the deadline. Maintaining and balancing various requests from stakeholders and assess the objectivity of the requests for prioritization. Knowledge of business vs analytics - understanding data from various systems for a deeper comprehension of a data structure based on subjects.  PERSONAL TRAITS & PEOPLE MANAGEMENT Safety-conscious Agile Creative Reliable Efficient Digital-driven Possess good people management skills with unquestionable teamwork spirit, integrity and demonstrate the highest level of professionalism to deliver the best customer\u2019s experience",
        {
            "entities": [
                [
                    638,
                    641,
                    "PROGLANG"
                ],
                [
                    646,
                    651,
                    "TOOL"
                ],
                [
                    2211,
                    2219,
                    "EDUCATION"
                ],
                [
                    2486,
                    2489,
                    "PROGLANG"
                ],
                [
                    2633,
                    2636,
                    "PROGLANG"
                ],
                [
                    2659,
                    2664,
                    "TOOL"
                ],
                [
                    2684,
                    2689,
                    "TOOL"
                ],
                [
                    2859,
                    2862,
                    "PROGLANG"
                ],
                [
                    2865,
                    2871,
                    "PROGLANG"
                ],
                [
                    2874,
                    2877,
                    "PROGLANG"
                ],
                [
                    2880,
                    2887,
                    "TOOL"
                ],
                [
                    2890,
                    2891,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "Open Position: Data Analytics Engineer (Fintech Company)  One of the recognised Fintech company in Malaysia is currently looking for Data Analytics Engineer to join them in the Kuala Lumpur office. You will be responsible to collect data, identify the patterns and customize databases to store data accordingly.  Key Responsibilities Include Good experience working as Data Engineer in an Analytics Team Work closely with stakeholders to understand business requirements and identify improvement opportunities using mathematical/statistical techniques Good experience in design, development, testing and deployment of new reporting and updates to the regional management team using BI Reporting and SQL reporting Good experience in data modelling, data mining, data processing with good analysis skills Good experience with analytics and reporting tools such as Excel, PowerBI, SQL, Tableau, and etc Self-driven with strong analytical and problem solving ability If you are interested, please send your updated CV to lai@btcrecruitment.com for a confidential discussion.  Visit us at www.btcrecruitment.com today.  #IT #InfomationTechnology #dataengineer #analytics #datamodelling #data #excel #SQL #PowerBI #tableau #cv #career #jobs #btcmalaysia #btcrecruitment #Malaysia",
        {
            "entities": [
                [
                    699,
                    702,
                    "PROGLANG"
                ],
                [
                    862,
                    867,
                    "TOOL"
                ],
                [
                    869,
                    876,
                    "TOOL"
                ],
                [
                    878,
                    881,
                    "PROGLANG"
                ],
                [
                    883,
                    890,
                    "TOOL"
                ],
                [
                    1188,
                    1193,
                    "TOOL"
                ],
                [
                    1195,
                    1198,
                    "PROGLANG"
                ],
                [
                    1200,
                    1207,
                    "TOOL"
                ],
                [
                    1209,
                    1216,
                    "TOOL"
                ]
            ]
        }
    ],
    [
        "Open Position: Data Engineer (Tech-based Company)  A Tech-based Company is looking for an enthusiastic and self-motivated Data Engineer who will ensure the smooth operation of a high volume data pipeline solutions and architecture. You will be working closely in a cross-functional environment, collaborating with Data Scientists, Product Managers, Engineering Teams and Business Stakeholders, providing the organization with analytical data.  Key Requirements Include Bachelor\u2019s degree or higher in an applicable field such as Computer Science, Statistics, Maths or similar Science or Engineering discipline Strong knowledge of SQL databases and strong coding skills with Python and data Cleansing In-depth knowledge of the Hadoop ecosystem, its various components, along with different tools including ETL, Spark, Hive, and Pig along with Python Experience using noSQL databases such as MongoDB and JSON Experience deploying and using cloud based data analytics visualization tools such as Looker, D3.js Proficient in data wrangling and preparation using Python, SQL, Spark and experience in working large data sets Validated analytical and problem-solving skills and implementing them in Big Data Experience worked in an agile environment If you are interested, please send your updated CV to shuba@btcrecruitment.com for a confidential discussion.  Only shortlisted candidate will be notified.  Visit us at www.btcrecruitment.com today.  #dataengineer #bigdata #hadoop #etl #python #datajobs #techjobs #career #jobseekers #jobopportunity #btcmalaysia #btcrecruitment",
        {
            "entities": [
                [
                    469,
                    477,
                    "EDUCATION"
                ],
                [
                    629,
                    632,
                    "PROGLANG"
                ],
                [
                    673,
                    679,
                    "PROGLANG"
                ],
                [
                    725,
                    731,
                    "TOOL"
                ],
                [
                    809,
                    814,
                    "TOOL"
                ],
                [
                    841,
                    847,
                    "PROGLANG"
                ],
                [
                    889,
                    896,
                    "TOOL"
                ],
                [
                    1057,
                    1063,
                    "PROGLANG"
                ],
                [
                    1065,
                    1068,
                    "PROGLANG"
                ],
                [
                    1070,
                    1075,
                    "TOOL"
                ],
                [
                    1466,
                    1472,
                    "TOOL"
                ],
                [
                    1479,
                    1485,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "Senior Data Engineering Advisor  Data Science is all about breaking new ground to enable businesses to answer their most urgent questions. Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand new methodologies, tools, statistical methods and models. What\u2019s more, we are in collaboration with leading academics, industry experts and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data.  Join us as a Senior Data Engineering Advisor on our Data Engineering team in Remote Malaysia to do the best work of your career and make a profound social impact.  Senior Advisor, Data Engineering  Data Science is all about breaking new ground to enable businesses to answer their most urgent questions. Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand new methodologies, tools, statistical methods and models. What\u2019s more, we are in collaboration with leading academics, industry experts and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data.  Join us to do the best work of your career and make a profound social impact as a Data Engineering Senior Advisor for our Analytics team in Malaysia .  What You\u2019ll Achieve  As a Data Engineering Advisor, you will evaluate business data to produce meaningful insights and metrics, identifying trends that improve business performance. You will encourage best practices and knowledge sharing within the organization, and as a trusted advisor to the business you will also end users to determine information requirements.  You will: Provide Analytics to Hardware Pricing, Product Management and other Center of Competence teams globally. On a day-to-day basis, work with the hardware Pricing Managers or Services Product Group (PDMs) Managers to support regular/ ad-hoc deliverables and automation Develop Analytical Solutions using Data techniques, Mathematical & Statistical approaches, Business Domain Context, Competitive & Market research Deliver recurring Business critical data, analysis, and insights efficiently in the form of executive dashboard / reports within defined SLA  Take the first step towards your dream career  Every Dell Technologies team member brings something unique to the table. Here\u2019s what we are looking for with this role:  Essential Requirements 8 to 12 years of experience as an expert in Data access and analysis, building data marts and has exposure to delivery of analytics projects Expert-level proficiency on tools like SQL \u2013 Intermediate / advanced querying skills. Exposure to MSBI stack desirable. Have experience in databases like Teradata/ Oracle/MS SQL & Tableau/PowerBI or other visualization tools Ability to understand and build APIs, basis the need of the analytical project Should have business acumen, ability to assess impact on business performance Chart out the data/analytics strategy roadmap for the business and execute them with minimal supervision  Desirable Requirements Exposure to scripting / programming languages like Python and web technologies a plus but not mandatory Any bachelors/advanced degree  Here\u2019s our story; now tell us yours  Dell Technologies helps organizations and individuals build a brighter digital tomorrow. Our company is made up of more than 150,000 people, located in over 180 locations around the world. We\u2019re proud to be a diverse and inclusive team and have an endless passion for our mission to drive human progress.  What\u2019s most important to us is that you are respected, feel like you can be yourself and have the opportunity to do the best work of your life -- while still having a life. We offer excellent benefits, bonus programs, flexible work arrangements, a variety of career development opportunities, employee resource groups, and much more.  We started with computers, but we didn\u2019t stop there. We are helping customers move into the future with multi-cloud, AI and machine learning through the most innovative technology and services portfolio for the data era. Join us and become a part of what\u2019s next in technology, starting today.  You can also learn more about us by reading our latest Diversity and Inclusion Report and our plan to make the world a better place by 2030 here.  Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Read the full Equal Employment Opportunity Policy here.  Job Id: R157108",
        {
            "entities": [
                [
                    2796,
                    2799,
                    "PROGLANG"
                ],
                [
                    2921,
                    2927,
                    "TOOL"
                ],
                [
                    2931,
                    2934,
                    "PROGLANG"
                ],
                [
                    2937,
                    2944,
                    "TOOL"
                ],
                [
                    2945,
                    2952,
                    "TOOL"
                ],
                [
                    3319,
                    3325,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "Company Description  At Western Digital, our vision is to power global innovation and push the boundaries of technology to make what you thought was once impossible, possible.  At our core, Western Digital is a company of problem solvers. People achieve extraordinary things given the right technology. For decades, we\u2019ve been doing just that. Our technology helped people put a man on the moon.  We are a key partner to some of the largest and highest growth organizations in the world. From energizing the most competitive gaming platforms, to enabling systems to make cities safer and cars smarter and more connected, to powering the data centers behind many of the world\u2019s biggest companies and public cloud, Western Digital is fueling a brighter, smarter future.  Binge-watch any shows, use social media or shop online lately? You\u2019ll find Western Digital supporting the storage infrastructure behind many of these platforms. And, that flash memory card that captures and preserves your most precious moments? That\u2019s us, too.  We offer an expansive portfolio of technologies, storage devices and platforms for business and consumers alike. Our data-centric solutions are comprised of the Western Digital\u00ae, G-Technology\u2122, SanDisk\u00ae and WD\u00ae brands.  Today\u2019s exceptional challenges require your unique skills. It\u2019s You & Western Digital. Together, we\u2019re the next BIG thing in data.  Job Description  Job Description  Essential Duties And Responsibilities Work with cross functional teams on data visualization. Deal with IT folks to setup data pipeline. Conduct advanced data analysis with machine learning (supervised & unsupervised) Explore, adopt, and introduce new data analytical method to the site and provide Creates and sustains the report and tracking record on the development progression, updating the management or interested parties on timely basis. Provide technical support and training to the business domain or the beginner on data analytics and visualization. Promoting the data analysis culture in the organization and populate the uses of data visualization and big data application. Dealing with external service provider on new data analytical approach and relevant training. Consult the training department on the data analytic training syllabus. Qualifications  Qualifications Degree or Master\u2019s in Data Science or any equivalent certification or training, which proven with relevant skillset and knowledge. Required Minimum 3 years in data visualization development. Fresh graduates are encouraged to apply. Added advantages if working with machine learning, especially the transfer learning and AI development. Preferred Work in manufacturing environment or any relevant field. Skills Strong data analytical skill. Familiar with SQL and Python. Added advantage with other programming like Java, ASP.Net and C++ Other data analytical platform, such as Matlab (added advantage). Data visualization platform Spotfire (added advantage) or other platform. Additional Information  Western Digital thrives on the power and potential of diversity. As a global company, we believe the most effective way to embrace the diversity of our customers and communities is to mirror it from within. We believe the fusion of various perspectives results in the best outcomes for our employees, our company, our customers, and the world around us. We are committed to an inclusive environment where every individual can thrive through a sense of belonging, respect and contribution.  Western Digital is committed to offering opportunities to applicants with disabilities and ensuring all candidates can successfully navigate our careers website and our hiring process. Please contact us at staffingsupport@wdc.com to advise us of your accommodation request. In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying.",
        {
            "entities": [
                [
                    2311,
                    2317,
                    "EDUCATION"
                ],
                [
                    2755,
                    2758,
                    "PROGLANG"
                ],
                [
                    2763,
                    2769,
                    "PROGLANG"
                ],
                [
                    2815,
                    2819,
                    "PROGLANG"
                ],
                [
                    2833,
                    2836,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "Job Description  ESSENTIAL DUTIES AND RESPONSIBILITIES:  Work with cross functional teams on data visualization. Deal with IT folks to setup data pipeline. Conduct advanced data analysis with machine learning (supervised & unsupervised) Explore, adopt, and introduce new data analytical method to the site and provide Creates and sustains the report and tracking record on the development progression, updating the management or interested parties on timely basis. Provide technical support and training to the business domain or the beginner on data analytics and visualization. Promoting the data analysis culture in the organization and populate the uses of data visualization and big data application. Dealing with external service provider on new data analytical approach and relevant training. Consult the training department on the data analytic training syllabus.  Qualifications  QUALIFICATIONS:  Degree or Master\u2019s in Data Science or any equivalent certification or training, which proven with relevant skillset and knowledge. REQUIRED:  Minimum 3 years in data visualization development. Fresh graduates are encouraged to apply. Added advantages if working with machine learning, especially the transfer learning and AI development. PREFERRED:  Work in manufacturing environment or any relevant field. SKILLS:  Strong data analytical skill. Familiar with SQL and Python. Added advantage with other programming like Java, ASP.Net and C++ Other data analytical platform, such as Matlab (added advantage). Data visualization platform Spotfire (added advantage) or other platform.  Additional Information  Western Digital thrives on the power and potential of diversity. As a global company, we believe the most effective way to embrace the diversity of our customers and communities is to mirror it from within. We believe the fusion of various perspectives results in the best outcomes for our employees, our company, our customers, and the world around us. We are committed to an inclusive environment where every individual can thrive through a sense of belonging, respect and contribution.    Western Digital is committed to offering opportunities to applicants with disabilities and ensuring all candidates can successfully navigate our careers website and our hiring process. Please contact us at staffingsupport@wdc.com to advise us of your accommodation request. In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying.",
        {
            "entities": [
                [
                    916,
                    922,
                    "EDUCATION"
                ],
                [
                    1366,
                    1369,
                    "PROGLANG"
                ],
                [
                    1374,
                    1380,
                    "PROGLANG"
                ],
                [
                    1426,
                    1430,
                    "PROGLANG"
                ],
                [
                    1444,
                    1447,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "To join one of the world's most exciting regional company |Pioneering a newly created data analytic and CoE business unit   About Our Client  Our client is a Regional Industrial company who has a strong regional presence and had been the industry market leaders to date. They had drafted out an exciting data-focused approached plan moving forward and is looking for the right talent to join their entity.  Job Description  They are seeking an individual to manage and lead the group's data and analytics platform. Some other responsibilities includes : Design/implement ETL, policies and procedures for the company and act as a change agent for any innovation forward Perform deep dive analytics and focus on process improvement in developing the data warehouse To improve and design enterprise-wide data architecture across multiple technology including cloud/hybrid architecture To be responsible of data management including sourcing, storing and automating certain processes Provide on going support and maintenance working closely with the IT department team to ensure continuous improvement  The Successful Applicant  In order to be successful, the aspiring candidate would need to have a strong data engineering background and have relevant tool set skills. Other essential criteria includes : Bachelor Degree in a related discipline At least 3-4 years in Data Engineering and Data Management background Familiar with data visualisation tools, Tableau, D3, JavaScript Technical skills of ETL, data modelling, data warehousing, hybrid architecture and other working knowledge of algorithms would be an added advantage Ability to grow and lead a team  What's On Offer  To join one of the world's most exciting regional company  Pioneering a newly created data analytic and CoE business unit  To join a fast-growing and data-rich company  Contact: Irwin Ng  Quote job ref: 4220430",
        {
            "entities": [
                [
                    1302,
                    1310,
                    "EDUCATION"
                ],
                [
                    1452,
                    1459,
                    "TOOL"
                ],
                [
                    1465,
                    1475,
                    "PROGLANG"
                ]
            ]
        }
    ],
    [
        "\u201cThe future workforce is an equal one \u2013 we are setting the goal to achieve a gender balanced workforce by 2025. Find out more here.\u201d https://www.accenture.com/my-en/about/inclusion-diversity/gender-equality. About Accenture Accenture is a global professional services company with leading capabilities in digital, cloud and security. Combining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Interactive, Technology and Operations services\u2014all powered by the world\u2019s largest network of Advanced Technology and Intelligent Operations centres. Our 506,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. We embrace the power of change to create value and shared success for our clients, people, shareholders, partners and communities. Visit us at www.accenture.com. Data Engineering Manager Responsibilities: Work in interdisciplinary teams that combine technical, business and data science competencies. Design and implement solutions around data warehouse implementation ranging from architecture, ETL processes, multidimensional modelling, data marts implementation. Integrate datasets and dataflows using a variety of best in class software as well as profile and analyze large and complex datasets from disparate sources Guide and direct junior developers Shape and advise on detailed technical design decisions. Develop scheduling scripts or configure load schedules Design and run unit tests. Perform bug diagnosis and fix. Migrate code between development and test environments. Participate in support of the development environment. Qualifications: 6 + years designing and implementing large scale data loading, manipulation, processing solutions. High proficiency in data integration package High proficiency in Snowflake, Wherescape, ETL, Informatica, or Talend Experience in streaming integration development Cloud development experience (e.g. AWS, Azure) Deep familiarity with RDBMS Strong proficiency in SQL Able to design and implement relational data models Good understanding of DevOps and Agile way of working Undergraduate degree at minimum in Comp Science/ Information Systems. Professional Skills: Eagerness to contribute in a team-oriented environment Ability to work creatively and analytically in a problem-solving environment Desire to work in an information systems environment Excellent leadership, communication (written and oral) and interpersonal skills You will also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career. Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.",
        {
            "entities": [
                [
                    1897,
                    1903,
                    "TOOL"
                ],
                [
                    1987,
                    1990,
                    "TOOL"
                ],
                [
                    1992,
                    1997,
                    "TOOL"
                ],
                [
                    2049,
                    2052,
                    "PROGLANG"
                ]
            ]
        }
    ]
]